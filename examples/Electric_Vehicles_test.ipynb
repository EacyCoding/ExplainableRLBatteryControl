{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfFSajq6Hnef"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/intelligent-environments-lab/CityLearn/blob/master/examples/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ9PAm8aHnel"
   },
   "source": [
    "# Electric Vehicles Test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load EV Environment\n",
    "\n",
    "Run the following code to check if the EV environment is up and running for a centralized and dummy agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_buildings'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcitylearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcitylearn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CityLearnEnv\n\u001B[0;32m      4\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcitylearn_2022_phase_all_plus_evs\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 5\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mCityLearnEnv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcentral_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m Agent(env)\n\u001B[0;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39mlearn(episodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\CityLearnEVs\\citylearn\\citylearn.py:107\u001B[0m, in \u001B[0;36mCityLearnEnv.__init__\u001B[1;34m(self, schema, root_directory, buildings, electric_vehicles, simulation_start_time_step, simulation_end_time_step, episode_time_steps, rolling_episode_split, random_episode_split, seconds_per_time_step, reward_function, central_agent, shared_observations, random_seed, **kwargs)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__rewards \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_seed \u001B[38;5;241m=\u001B[39m random_seed\n\u001B[0;32m    106\u001B[0m root_directory, buildings, electric_vehicles, episode_time_steps, rolling_episode_split, random_episode_split, \\\n\u001B[1;32m--> 107\u001B[0m     seconds_per_time_step, reward_function, central_agent, shared_observations, episode_tracker \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbuildings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuildings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m        \u001B[49m\u001B[43melectric_vehicles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43melectric_vehicles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m        \u001B[49m\u001B[43msimulation_start_time_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msimulation_start_time_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m        \u001B[49m\u001B[43msimulation_end_time_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msimulation_end_time_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepisode_time_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepisode_time_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrolling_episode_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrolling_episode_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_episode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_episode_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseconds_per_time_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseconds_per_time_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreward_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreward_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcentral_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcentral_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshared_observations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshared_observations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_directory \u001B[38;5;241m=\u001B[39m root_directory\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuildings \u001B[38;5;241m=\u001B[39m buildings\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\CityLearnEVs\\citylearn\\citylearn.py:1581\u001B[0m, in \u001B[0;36mCityLearnEnv._load\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m   1579\u001B[0m     reward_function_name \u001B[38;5;241m=\u001B[39m reward_function_type\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1580\u001B[0m     reward_function_constructor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(importlib\u001B[38;5;241m.\u001B[39mimport_module(reward_function_module), reward_function_name)\n\u001B[1;32m-> 1581\u001B[0m     reward_function \u001B[38;5;241m=\u001B[39m reward_function_constructor(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mreward_function_attributes)\n\u001B[0;32m   1583\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m   1584\u001B[0m     root_directory, buildings, evs, episode_time_steps, rolling_episode_split, random_episode_split,\n\u001B[0;32m   1585\u001B[0m     seconds_per_time_step, reward_function, central_agent, shared_observations, episode_tracker\n\u001B[0;32m   1586\u001B[0m )\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'n_buildings'"
     ]
    }
   ],
   "source": [
    "from citylearn.agents.base import DummyAgent as Agent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "dataset_name = 'citylearn_2022_phase_all_plus_evs'\n",
    "env = CityLearnEnv(dataset_name, central_agent=True)\n",
    "model = Agent(env)\n",
    "model.learn(episodes=1)\n",
    "\n",
    "# print cost functions at the end of episode\n",
    "kpis = model.env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value').round(3)\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Control (Baseline)\n",
    "\n",
    "Run the following to simulate an environment where the storage systems and heat pumps are not controlled (baseline). The storage actions prescribed will be 0.0 and the heat pump will have no action, i.e. `None`, causing it to deliver the ideal load in the building time series files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn.agents.base import DummyAgent as Agent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "dataset_name = 'citylearn_challenge_2023_phase_2_local_evaluation'\n",
    "env = CityLearnEnv(dataset_name, central_agent=True)\n",
    "model = Agent(env)\n",
    "model.learn(episodes=1)\n",
    "\n",
    "# print cost functions at the end of episode\n",
    "kpis = model.env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value').round(3)\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F93k9GV7Hnep"
   },
   "source": [
    "## Centralized RBC\n",
    "Run the following to simulate an environment controlled by centralized RBC agent for a single episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "aFijYpHLHneq",
    "outputId": "0914afd7-c811-4748-a252-806aaaa990d5"
   },
   "outputs": [],
   "source": [
    "from citylearn.agents.rbc import BasicRBC as Agent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "dataset_name = 'citylearn_challenge_2023_phase_2_local_evaluation'\n",
    "env = CityLearnEnv(dataset_name, central_agent=True)\n",
    "model = Agent(env)\n",
    "model.learn(episodes=1)\n",
    "\n",
    "# print cost functions at the end of episode\n",
    "kpis = model.env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value').round(3)\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGSdXQRCHner"
   },
   "source": [
    "## Decentralized-Independent SAC\n",
    "\n",
    "Run the following to simulate an environment controlled by decentralized-independent SAC agents for 1 training episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "CLYpZlBQHnes",
    "outputId": "6306ace0-7cab-4f06-f9c3-fd7c5ec5db01"
   },
   "outputs": [],
   "source": [
    "from citylearn.agents.sac import SAC as Agent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "dataset_name = 'citylearn_challenge_2023_phase_2_local_evaluation'\n",
    "env = CityLearnEnv(dataset_name, central_agent=False)\n",
    "model = Agent(env)\n",
    "model.learn(episodes=2, deterministic_finish=True)\n",
    "\n",
    "# print cost functions at the end of episode\n",
    "kpis = model.env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value').round(3)\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31AHVfD4Hnes"
   },
   "source": [
    "## Decentralized-Cooperative MARLISA\n",
    "\n",
    "Run the following to simulate an environment controlled by decentralized-cooperative MARLISA agents for 1 training episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "oBkmRYWmHnet",
    "outputId": "5eb03530-93de-4b4c-d09c-a165ee607d54"
   },
   "outputs": [],
   "source": [
    "from citylearn.agents.marlisa import MARLISA as Agent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "dataset_name = 'citylearn_challenge_2023_phase_2_local_evaluation'\n",
    "env = CityLearnEnv(dataset_name, central_agent=False)\n",
    "model = Agent(env)\n",
    "model.learn(episodes=2, deterministic_finish=True)\n",
    "\n",
    "kpis = model.env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value').round(3)\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XY-UbGD6Hnet"
   },
   "source": [
    "## Stable Baselines3 Reinforcement Learning Algorithms\n",
    "\n",
    "Install the latest version of Stable Baselines3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tg7U22iEHneu"
   },
   "outputs": [],
   "source": [
    "%pip install shimmy==0.2.1\n",
    "%pip install stable-baselines3==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh31WOTeHneu"
   },
   "source": [
    "Before the environment is ready for use in Stable Baselines3, it needs to be wrapped. Firstly, wrap the environment using the `NormalizedObservationWrapper` (see [docs](https://www.citylearn.net/api/citylearn.wrappers.html#citylearn.wrappers.NormalizedObservationWrapper)) to ensure that observations served to the agent are min-max normalized between [0, 1] and cyclical observations e.g. hour, are encoded using the cosine transformation.\n",
    "\n",
    "Next, we wrap with the `StableBaselines3Wrapper` (see [docs](https://www.citylearn.net/api/citylearn.wrappers.html#citylearn.wrappers.StableBaselines3Wrapper)) that ensures observations, actions and rewards are served in manner that is compatible with Stable Baselines3 interface.\n",
    "\n",
    "For the following Stable Baselines3 example, the `baeda_3dem` dataset that support building temperature dynamics is used.\n",
    "\n",
    "> ⚠️ **NOTE**: `central_agent` in the `env` must be `True` when using Stable Baselines3  as it does not support multi-agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "pmhJWbgwHnev",
    "outputId": "fbe45090-51b7-4e31-ec9b-cbc647e0e397"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.sac import SAC as Agent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.wrappers import NormalizedObservationWrapper, StableBaselines3Wrapper\n",
    "\n",
    "dataset_name = 'citylearn_challenge_2023_phase_2_local_evaluation'\n",
    "env = CityLearnEnv(dataset_name, central_agent=True)\n",
    "env = NormalizedObservationWrapper(env)\n",
    "env = StableBaselines3Wrapper(env)\n",
    "model = Agent('MlpPolicy', env)\n",
    "episodes = 2\n",
    "model.learn(total_timesteps=env.time_steps*episodes)\n",
    "\n",
    "# evaluate\n",
    "observations = env.reset()\n",
    "\n",
    "while not env.done:\n",
    "    actions, _ = model.predict(observations, deterministic=True)\n",
    "    observations, _, _, _ = env.step(actions)\n",
    "\n",
    "kpis = env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value').round(3)\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d13602916ce501dab33551801634a98323f75b1378db411e4ca12af6dc15d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
