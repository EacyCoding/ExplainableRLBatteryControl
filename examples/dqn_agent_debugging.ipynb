{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681b71d8",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81f853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKER_ID: 0 CUDA_VISIBLE_DEVICES: MIG-f26f55f4-95ca-5a94-853c-d922a3dbfde6\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 13:07:15.672684: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-17 13:07:15.696818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758107235.724918 1868075 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758107235.733470 1868075 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758107235.754394 1868075 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758107235.754410 1868075 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758107235.754413 1868075 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758107235.754415 1868075 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-17 13:07:15.761375: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.7\n",
      "Torch : 2.7.0+cu126\n",
      "CityLearn: 2.4.1\n",
      "Optuna installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/hkfs/home/haicore/iai/cj9272/citylearn_env/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "# System operations\n",
    "import os\n",
    "os.environ[\"OPTUNA_WORKER_ID\"] = os.getenv(\"OPTUNA_WORKER_ID\", \"0\")\n",
    "# pin GPU per kernel or set \"\" to force CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv(\"CUDA_VISIBLE_DEVICES\", \"0\")\n",
    "# reduce thread contention\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "# now import libs\n",
    "WORKER_ID = int(os.getenv(\"OPTUNA_WORKER_ID\", \"0\"))\n",
    "print(\"WORKER_ID:\", WORKER_ID, \"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "\n",
    "# Type hinting\n",
    "from typing import Any, List, Mapping, Tuple, Union\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import torch as th\n",
    "import copy, time, json, pickle\n",
    "\n",
    "# CityLearn\n",
    "import citylearn\n",
    "from citylearn.data import DataSet\n",
    "from citylearn.wrappers import NormalizedObservationWrapper, StableBaselines3Wrapper\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "# Baseline RL algorithms\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Utils\n",
    "from utils.env_utils import DiscretizeActionWrapper, keep_only_electrical_storage, keep_only_core_observations\n",
    "\n",
    "print('Python:', sys.version.split()[0])\n",
    "print('Torch :', th.__version__)\n",
    "print('CityLearn:', citylearn.__version__)\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"optuna\", \"optuna-dashboard\"])\n",
    "print(\"Optuna installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2f110",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4530515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'citylearn_challenge_2023_phase_3_1'  # adjust if needed\n",
    "ROOT_DIR = r'/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1'\n",
    "LOG_DIR = r'/hkfs/home/haicore/iai/cj9272/logs/dqn'\n",
    "REWARD_FN = {  # CostReward \n",
    "    'type': 'citylearn.reward_function.CostReward',\n",
    "    'attributes': {}\n",
    "}\n",
    "PRICING_FILE = 'pricing_germany_2023_june_to_august.csv'\n",
    "ACTION_LABELS = ['100%_discharge','50%_discharge','idle','50%_charge','100%_charge']\n",
    "NAME_TO_FRAC = {\n",
    "    '100%_discharge': -1.0, \n",
    "    # energy = -1*capacity,\n",
    "    # diff = soc_init-0.2 e.g. diff = 0.8\n",
    "    # -(diff*capacity*sqrt(0.95)) e.g. -0.77\n",
    "    # max_output_power = 3.32 * capacity_power_curve values \n",
    "    # (Given the current SoC, look up the max allowed output power fraction\n",
    "    # from the curve (by linear interpolation) and multiply \n",
    "    # by the system’s nominal power to get max_output_power)\n",
    "    # energy = max(-max_output_power, -(diff*capacity*sqrt(0.95)), -1*capacity)\n",
    "    '50%_discharge': -0.5,\n",
    "    'idle': 0.0,\n",
    "    '50%_charge': 0.5,\n",
    "    '100%_charge': 1.0,\n",
    "}\n",
    "INT_TO_FRAC = np.array([NAME_TO_FRAC[n] for n in ACTION_LABELS], dtype=np.float32)\n",
    "EVAL_EPISODES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcff422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [\n",
    "    # building_df\n",
    "    'month', 'hour', 'day_type', 'daylight_savings_status',\n",
    "    'indoor_dry_bulb_temperature',\n",
    "    'average_unmet_cooling_setpoint_difference',\n",
    "    'indoor_relative_humidity',\n",
    "    'non_shiftable_load', 'dhw_demand',\n",
    "    'cooling_demand', 'heating_demand',\n",
    "    'solar_generation', 'occupant_count',\n",
    "    'indoor_dry_bulb_temperature_cooling_set_point',\n",
    "    'indoor_dry_bulb_temperature_heating_set_point', 'hvac_mode',\n",
    "    # weather_df\n",
    "    'outdoor_dry_bulb_temperature',\n",
    "    'outdoor_relative_humidity',\n",
    "    'diffuse_solar_irradiance',\n",
    "    'direct_solar_irradiance',\n",
    "    'outdoor_dry_bulb_temperature_predicted_1',\n",
    "    'outdoor_dry_bulb_temperature_predicted_2',\n",
    "    'outdoor_dry_bulb_temperature_predicted_3',\n",
    "    'outdoor_relative_humidity_predicted_1',\n",
    "    'outdoor_relative_humidity_predicted_2',\n",
    "    'outdoor_relative_humidity_predicted_3',\n",
    "    'diffuse_solar_irradiance_predicted_1',\n",
    "    'diffuse_solar_irradiance_predicted_2',\n",
    "    'diffuse_solar_irradiance_predicted_3',\n",
    "    'direct_solar_irradiance_predicted_1',\n",
    "    'direct_solar_irradiance_predicted_2',\n",
    "    'direct_solar_irradiance_predicted_3',\n",
    "    # carbon_df \n",
    "    'carbon_intensity',\n",
    "    # pricing_df\n",
    "    'electricity_pricing',\n",
    "    'electricity_pricing_predicted_1',\n",
    "    'electricity_pricing_predicted_2',\n",
    "    'electricity_pricing_predicted_3'\n",
    "]\n",
    "bld_cols = [\n",
    "            'month', 'hour', 'day_type', 'daylight_savings_status',\n",
    "            'indoor_dry_bulb_temperature',\n",
    "            'average_unmet_cooling_setpoint_difference',\n",
    "            'indoor_relative_humidity', 'non_shiftable_load',\n",
    "            'dhw_demand', 'cooling_demand', 'heating_demand',\n",
    "            'solar_generation', 'occupant_count',\n",
    "            'indoor_dry_bulb_temperature_cooling_set_point',\n",
    "            'indoor_dry_bulb_temperature_heating_set_point',\n",
    "            'hvac_mode'\n",
    "]\n",
    "wth_cols = [\n",
    "    'outdoor_dry_bulb_temperature',\n",
    "    'outdoor_relative_humidity',\n",
    "    'diffuse_solar_irradiance',\n",
    "    'direct_solar_irradiance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b053b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Go here /home/iai/cj9272/.cache/citylearn/v2.4.1/datasets/citylearn_challenge_2023_phase_3_1/schema.json \n"
     ]
    }
   ],
   "source": [
    "# --- Load schema ---\n",
    "dataset = DataSet()\n",
    "schema = dataset.get_schema(DATASET_NAME)\n",
    "schema['root_directory'] = ROOT_DIR\n",
    "schema['reward_function'] = REWARD_FN\n",
    "\n",
    "price_file = PRICING_FILE # Set pricing file\n",
    "if 'buildings' not in schema:\n",
    "    raise RuntimeError(\"schema does not contain 'buildings' (make sure schema is loaded first)\")\n",
    "for bname, bconf in schema['buildings'].items():\n",
    "    bconf['pricing'] = price_file\n",
    "\n",
    "schema = keep_only_electrical_storage(schema) # Activate only the electrical storage control (fix \"Expected 18 actions but got 1\")\n",
    "schema = keep_only_core_observations(schema, extra_keep=['carbon_intensity', 'non_shiftable_load'], drop_predictions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec41d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLoggerCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, save_csv=True, csv_path=\"/mnt/data/train_steps.csv\"):\n",
    "        super().__init__(verbose)\n",
    "        self.rows = []\n",
    "        self.losses = []\n",
    "        self.loss_timesteps = []\n",
    "        self.episode_rewards = []\n",
    "        self._current_ep_rewards = []\n",
    "        self._current_ep_counts = []\n",
    "        self._current_step_in_episode = []\n",
    "        self.df = pd.DataFrame()\n",
    "        self.ep_df = pd.DataFrame()\n",
    "        self._obs_names = None\n",
    "        self.save_csv = save_csv\n",
    "        self.csv_path = csv_path\n",
    "\n",
    "    def _get_citylearn_env_for_idx(self, idx: int):\n",
    "        from citylearn.citylearn import CityLearnEnv\n",
    "        env = self.training_env\n",
    "        try:\n",
    "            sub = env.envs[idx]\n",
    "        except Exception:\n",
    "            sub = getattr(env, \"env\", getattr(env, \"unwrapped\", env))\n",
    "        seen = set()\n",
    "        cur = sub\n",
    "        while cur is not None and id(cur) not in seen:\n",
    "            if isinstance(cur, CityLearnEnv):\n",
    "                return cur\n",
    "            seen.add(id(cur))\n",
    "            cur = getattr(cur, \"env\", getattr(cur, \"unwrapped\", None))\n",
    "        return None\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        try:\n",
    "            n_envs = self.training_env.num_envs\n",
    "        except AttributeError:\n",
    "            n_envs = 1\n",
    "        self._current_ep_rewards = [0.0] * n_envs\n",
    "        self._current_ep_counts = [1] * n_envs\n",
    "        self._current_step_in_episode = [0] * n_envs\n",
    "        # capture observation names (single-building case)\n",
    "        try:\n",
    "            base = self._get_citylearn_env_for_idx(0)\n",
    "            if base is not None:\n",
    "                self._obs_names = list(base.observation_names[0])\n",
    "        except Exception:\n",
    "            self._obs_names = None\n",
    "        super()._on_training_start()\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        obs_vec = self.locals.get(\"new_obs\")\n",
    "        acts    = self.locals.get(\"actions\")\n",
    "        rews    = self.locals.get(\"rewards\")\n",
    "        dones   = self.locals.get(\"dones\")\n",
    "        step    = int(self.num_timesteps)\n",
    "\n",
    "        loss_val = self.logger.name_to_value.get(\"train/loss\")\n",
    "        if loss_val is not None:\n",
    "            self.losses.append(float(loss_val))\n",
    "            self.loss_timesteps.append(step)\n",
    "\n",
    "        for idx, (obs, act, rew, done) in enumerate(zip(obs_vec, acts, rews, dones)):\n",
    "            row = {}\n",
    "            # Basic step metadata\n",
    "            row.update({\n",
    "                \"global_step\": step,\n",
    "                \"env_id\": idx,\n",
    "                \"episode\": self._current_ep_counts[idx],\n",
    "                \"action_id\": int(act),\n",
    "                \"reward\": float(rew),\n",
    "            })\n",
    "\n",
    "            # Optional: action label & mapped fraction\n",
    "            try:\n",
    "                a_id = int(act)\n",
    "                row['action_label'] = ACTION_LABELS[a_id]\n",
    "                row['action_frac'] = float(INT_TO_FRAC[a_id])\n",
    "            except Exception:\n",
    "                row['action_label'] = None\n",
    "                row['action_frac'] = None\n",
    "\n",
    "            # Pull CityLearn internals for consistent indexing\n",
    "            try:\n",
    "                base = self._get_citylearn_env_for_idx(idx)\n",
    "                if base is not None:\n",
    "                    b = base.buildings[0]\n",
    "                    t  = b.time_step\n",
    "                    tp = max(0, t-1)  # previous step = the one your obs net_load refers to\n",
    "\n",
    "                    # Robust chargers\n",
    "                    chargers_arr = getattr(b, \"_Building__chargers_electricity_consumption\", None)\n",
    "                    chargers_tp = float(chargers_arr[tp]) if chargers_arr is not None else float('nan')\n",
    "                    chargers_t  = float(chargers_arr[t])  if chargers_arr is not None else float('nan')\n",
    "\n",
    "                    # Component loads on tp (this is the consistent balance slice)\n",
    "                    row.update({\n",
    "                        \"price\": float(b.pricing.electricity_pricing[tp]),\n",
    "                        \"net_load\": float(b.net_electricity_consumption[tp]),\n",
    "                        \"non_shiftable_load\": float(b.non_shiftable_load_device.electricity_consumption[tp]),\n",
    "                        \"cooling_load\": float(b.cooling_device.electricity_consumption[tp]),\n",
    "                        \"heating_load\": float(b.heating_device.electricity_consumption[tp]),\n",
    "                        \"dhw_load\": float(b.dhw_device.electricity_consumption[tp]),\n",
    "                        \"chargers_load\": chargers_tp,\n",
    "                        \"storage_load\": float(b.electrical_storage.electricity_consumption[tp]),\n",
    "                        \"solar\": float(b.solar_generation[tp]),  # negative for generation\n",
    "                        \"battery_soc\": float(b.electrical_storage.soc[tp]),\n",
    "                        \"battery_energy_balance\": float(b.electrical_storage.energy_balance[tp]),\n",
    "                        \"simulate_power_outage\": bool(getattr(b, 'simulate_power_outage', False)),\n",
    "                        \"power_outage\": bool(getattr(b, 'power_outage', False)),\n",
    "                    })\n",
    "\n",
    "                # If base is None, we still keep the obs-based fields we already wrote\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            self.rows.append(row)\n",
    "\n",
    "            # bookkeeping\n",
    "            self._current_ep_rewards[idx] += float(rew)\n",
    "            self._current_step_in_episode[idx] += 1\n",
    "            if done:\n",
    "                self.episode_rewards.append(self._current_ep_rewards[idx])\n",
    "                self._current_ep_rewards[idx] = 0.0\n",
    "                self._current_step_in_episode[idx] = 0\n",
    "                self._current_ep_counts[idx] += 1\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        self.df = pd.DataFrame(self.rows)\n",
    "        self.ep_df = pd.DataFrame({\n",
    "            \"episode_global\": range(1, len(self.episode_rewards) + 1),\n",
    "            \"return\": self.episode_rewards\n",
    "        })\n",
    "        super()._on_training_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d02cb",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d722e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1\n",
      "Dataset '/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1' copied to '/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1/../../../../results/2025-09-17_13-07-24'\n",
      "['electrical_storage']\n",
      "Battery capacity: 4.0\n",
      "Battery nominal power: 3.32\n",
      "Action names: [['electrical_storage']]\n",
      "Action space: Discrete(5)\n",
      "Battery attributes: ['DEFAULT_RANDOM_SEED_RANGE', 'DEFAULT_SECONDS_PER_TIME_STEP', '_Battery__capacity_loss_coefficient', '_Battery__capacity_power_curve', '_Battery__depth_of_discharge', '_Battery__power_efficiency_curve', '_Battery__time_step_ratio', '_Device__efficiency', '_ElectricDevice__electricity_consumption', '_ElectricDevice__nominal_power', '_Environment__episode_tracker', '_Environment__random_seed', '_Environment__seconds_per_time_step', '_Environment__time_step', '_Environment__uid', '_StorageDevice__capacity', '_StorageDevice__energy_balance', '_StorageDevice__initial_soc', '_StorageDevice__loss_coefficient', '_StorageDevice__soc', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_autosize_config', '_capacity_history', '_efficiency_history', '_get_property_value', 'as_dict', 'autosize', 'autosize_config', 'available_nominal_power', 'capacity', 'capacity_history', 'capacity_loss_coefficient', 'capacity_power_curve', 'charge', 'degrade', 'degraded_capacity', 'depth_of_discharge', 'efficiency', 'efficiency_history', 'electricity_consumption', 'energy_balance', 'energy_init', 'episode_tracker', 'force_set_soc', 'get_current_efficiency', 'get_max_input_power', 'get_max_output_power', 'get_metadata', 'initial_soc', 'loss_coefficient', 'next_time_step', 'nominal_power', 'numpy_random_state', 'power_efficiency_curve', 'random_seed', 'reset', 'reset_time_step', 'round_trip_efficiency', 'seconds_per_time_step', 'set_energy_balance', 'soc', 'time_step', 'time_step_ratio', 'uid', 'update_electricity_consumption']\n",
      "Initial SOC: 0.19999999999999996\n",
      "SOC (full array): [0.2 0.  0.  ... 0.  0.  0. ]\n",
      "First 20 SOC values: [0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0. ]\n",
      "Current timestep: 0\n",
      "Current SOC: 0.2\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Keep only one building: 1-D action\n",
    "one_building = \"Building_1\"\n",
    "schema_1b = dict(schema)  # shallow copy\n",
    "schema_1b['buildings'] = {k: v for k, v in schema['buildings'].items() if k == one_building}\n",
    "if not schema_1b['buildings']:\n",
    "    raise RuntimeError(f\"{one_building} not found in schema['buildings']\")\n",
    "\n",
    "train_env = CityLearnEnv(schema_1b, central_agent=True)\n",
    "train_env = NormalizedObservationWrapper(train_env)\n",
    "train_env = StableBaselines3Wrapper(train_env)\n",
    "# Discretize action space for DQN\n",
    "train_env = DiscretizeActionWrapper(train_env, n_bins=5)\n",
    "train_env = Monitor(train_env)\n",
    "\n",
    "b = train_env.unwrapped.buildings[0]\n",
    "print(b.active_actions)\n",
    "print(\"Battery capacity:\", b.electrical_storage.capacity)\n",
    "print(\"Battery nominal power:\", getattr(b.electrical_storage, \"nominal_power\", \"N/A\"))\n",
    "print(\"Action names:\", train_env.unwrapped.action_names)\n",
    "print(\"Action space:\", train_env.action_space)\n",
    "\n",
    "print(\"Battery attributes:\", dir(b.electrical_storage))\n",
    "print(\"Initial SOC:\", b.electrical_storage.initial_soc)\n",
    "print(\"SOC (full array):\", b.electrical_storage.soc)\n",
    "print(\"First 20 SOC values:\", b.electrical_storage.soc[:20])\n",
    "print(\"Current timestep:\", b.time_step)\n",
    "print(\"Current SOC:\", b.electrical_storage.soc[b.time_step])\n",
    "\n",
    "\n",
    "train_callback = TrainLoggerCallback()\n",
    "\n",
    "\n",
    "T = train_env.unwrapped.time_steps  # 2208\n",
    "num_episodes = 1 # 50\n",
    "TOTAL_TIMESTEPS = num_episodes * T # TODO: change back\n",
    "\"\"\"\n",
    "model = DQN(\n",
    "    policy='MlpPolicy',\n",
    "    env=train_env,\n",
    "    seed=0,\n",
    "    #learning_starts=1000,\n",
    "    learning_rate=1.1131267357743944e-05,\n",
    "    gamma=0.9617017861578802,\n",
    "    buffer_size=150000,\n",
    "    batch_size=64,\n",
    "    tau=0.05065165487856718,\n",
    "    target_update_interval=3500,\n",
    "    train_freq=1,\n",
    "    gradient_steps=3,\n",
    "    exploration_fraction=0.2847232543663558,\n",
    "    exploration_final_eps=0.028934430496645687,\n",
    "    learning_starts=1000,\n",
    "    verbose=1, # logging: info\n",
    "    policy_kwargs=dict(net_arch=[512, 512], activation_fn=th.nn.ReLU),\n",
    ")\n",
    "\"\"\"\n",
    "model = DQN(\n",
    "    policy='MlpPolicy',\n",
    "    env=train_env,\n",
    "    seed=0,\n",
    "    learning_rate=0.0002752350841138598,\n",
    "    gamma=0.9851293040985031,\n",
    "    buffer_size=125000,\n",
    "    batch_size=256,\n",
    "    tau=0.05065165487856718,\n",
    "    target_update_interval=3500,\n",
    "    train_freq=5,\n",
    "    gradient_steps=4,\n",
    "    exploration_fraction=0.18063198209981218,\n",
    "    exploration_final_eps=0.05601773593918628,\n",
    "    learning_starts=1000,\n",
    "    verbose=1, # logging: info\n",
    "    policy_kwargs=dict(net_arch=[512, 512], activation_fn=th.nn.ReLU),\n",
    ")\n",
    "TRAINING_FILE = \"dqn_03\" # num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d8a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed for 2208 steps: 113.15 seconds\n",
      "---------------Train callback: \n",
      "       global_step  env_id  episode  action_id    reward    action_label  \\\n",
      "0               1       0        1          4 -0.568172     100%_charge   \n",
      "1               2       0        1          3 -0.049786      50%_charge   \n",
      "2               3       0        1          2 -0.028231            idle   \n",
      "3               4       0        1          1  0.000000   50%_discharge   \n",
      "4               5       0        1          1  0.000000   50%_discharge   \n",
      "...           ...     ...      ...        ...       ...             ...   \n",
      "2205         2206       0        1          1 -0.201297   50%_discharge   \n",
      "2206         2207       0        1          1 -0.125207   50%_discharge   \n",
      "2207         2208       0        2          1 -0.092640   50%_discharge   \n",
      "2208         2209       0        2          0 -0.039034  100%_discharge   \n",
      "2209         2210       0        2          0 -0.028231  100%_discharge   \n",
      "\n",
      "      action_frac    price  net_load  non_shiftable_load  ...  battery_soc  \\\n",
      "0             1.0  0.08415  7.646992            1.068808  ...     0.961749   \n",
      "1             0.5  0.07430  0.710209            0.344522  ...     0.998025   \n",
      "2             0.0  0.07010  0.423126            0.338227  ...     0.997926   \n",
      "3            -0.5  0.06672 -0.564632            0.334329  ...     0.750845   \n",
      "4            -0.5  0.06770 -1.290487            0.348094  ...     0.316922   \n",
      "...           ...      ...       ...                 ...  ...          ...   \n",
      "2205         -0.5  0.12550  1.898490            0.552855  ...     0.198168   \n",
      "2206         -0.5  0.08415  0.415611            0.356269  ...     0.200000   \n",
      "2207         -0.5  0.08415  1.246832            1.068808  ...     0.199980   \n",
      "2208         -1.0  0.07430  0.556836            0.344522  ...     0.199960   \n",
      "2209         -1.0  0.07010  0.423126            0.338227  ...     0.199940   \n",
      "\n",
      "      battery_energy_balance  simulate_power_outage  power_outage  net_load_t  \\\n",
      "0                   3.200080                   True         False    0.000000   \n",
      "1                   0.153373                   True         False    0.000000   \n",
      "2                   0.000000                   True         False    0.000000   \n",
      "3                  -0.926753                   True         False    0.000000   \n",
      "4                  -1.660000                   True         False    0.000000   \n",
      "...                      ...                    ...           ...         ...   \n",
      "2205                0.000000                   True         False    0.000000   \n",
      "2206                0.000000                   True         False    0.415611   \n",
      "2207                0.000000                   True         False    0.000000   \n",
      "2208                0.000000                   True         False    0.000000   \n",
      "2209                0.000000                   True         False    0.000000   \n",
      "\n",
      "      storage_load_t  battery_soc_t  non_shiftable_load_t  solar_t  \\\n",
      "0                0.0            0.0              0.000000     -0.0   \n",
      "1                0.0            0.0              0.000000     -0.0   \n",
      "2                0.0            0.0              0.000000     -0.0   \n",
      "3                0.0            0.0              0.000000     -0.0   \n",
      "4                0.0            0.0              0.000000     -0.0   \n",
      "...              ...            ...                   ...      ...   \n",
      "2205             0.0            0.0              0.000000     -0.0   \n",
      "2206             0.0            0.2              0.356269     -0.0   \n",
      "2207             0.0            0.0              0.000000     -0.0   \n",
      "2208             0.0            0.0              0.000000     -0.0   \n",
      "2209             0.0            0.0              0.000000     -0.0   \n",
      "\n",
      "      chargers_load_t  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "...               ...  \n",
      "2205              0.0  \n",
      "2206              0.0  \n",
      "2207              0.0  \n",
      "2208              0.0  \n",
      "2209              0.0  \n",
      "\n",
      "[2210 rows x 26 columns]\n",
      "---------------Episode rewards: \n",
      "    episode_global      return\n",
      "0               1 -281.402291\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=train_callback)\n",
    "print(f\"Total time elapsed for {TOTAL_TIMESTEPS} steps: {(time.time()-start_time):.2f} seconds\")\n",
    "model.save(TRAINING_FILE)\n",
    "\n",
    "print(\"---------------Train callback: \\n\", train_callback.df)\n",
    "print(\"---------------Episode rewards: \\n\", train_callback.ep_df)\n",
    "# Save training logs\n",
    "TRAIN_STEPS_FILE = os.path.join(LOG_DIR, \"dqn_train_steps_03.csv\") # num\n",
    "TRAIN_EPISODES_FILE = os.path.join(LOG_DIR, \"dqn_train_episodes_03.csv\") # num\n",
    "train_callback.df.to_csv(TRAIN_STEPS_FILE, index=False)\n",
    "train_callback.ep_df.to_csv(TRAIN_EPISODES_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85b0640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 SoC values after training:\n",
      "[np.float32(0.2), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
      "Current timestep: 0\n",
      "Current SoC: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Print SoC for the first 10 timesteps after training\n",
    "b = train_env.unwrapped.buildings[0]\n",
    "print(\"First 10 SoC values after training:\")\n",
    "print([b.electrical_storage.soc[t] for t in range(min(100, len(b.electrical_storage.soc)))])\n",
    "print(\"Current timestep:\", b.time_step)\n",
    "print(\"Current SoC:\", b.electrical_storage.soc[b.time_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9d62c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share commanded discharge: 0.6203619909502263\n",
      "…but realized zero (empty/limited): 0.4239819004524887\n",
      "…and realized discharge: 0.19638009049773755\n",
      "corr(action_frac, storage_load): 0.6110465906092021\n"
     ]
    }
   ],
   "source": [
    "# View first rows from training logs\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"train_steps.csv\")\n",
    "import numpy as np\n",
    "\n",
    "eps = 1e-4\n",
    "cmd_neg = df['action_frac'] < 0\n",
    "real_neg = df['storage_load'] < -eps\n",
    "real_zero = df['storage_load'].abs() <= eps\n",
    "\n",
    "print(\"share commanded discharge:\", cmd_neg.mean())\n",
    "print(\"…but realized zero (empty/limited):\", (cmd_neg & real_zero).mean())\n",
    "print(\"…and realized discharge:\", (cmd_neg & real_neg).mean())\n",
    "\n",
    "# correlation: do commands actually move the battery?\n",
    "print(\"corr(action_frac, storage_load):\", df[['action_frac','storage_load']].corr().iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbc354",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12693856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1\n",
      "Dataset '/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1' copied to '/hkfs/home/haicore/iai/cj9272/Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1/../../../../results/2025-09-17_13-07-35'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "DQN model loaded from /hkfs/home/haicore/iai/cj9272/dqn_03\n"
     ]
    }
   ],
   "source": [
    "schema_eval = copy.deepcopy(schema_1b)\n",
    "eval_env = CityLearnEnv(schema_eval, central_agent=True)\n",
    "eval_env = NormalizedObservationWrapper(eval_env)\n",
    "eval_env = StableBaselines3Wrapper(eval_env)\n",
    "eval_env = DiscretizeActionWrapper(eval_env, n_bins=5)\n",
    "\n",
    "model = DQN.load(TRAINING_FILE, env=eval_env)\n",
    "print(f\"DQN model loaded from {os.path.abspath(TRAINING_FILE)}\")\n",
    "EVAL_FILE = os.path.join(LOG_DIR, \"dqn_eval_01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0fa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval: collect discrete actions and rewards per step\n",
    "def eval_dqn(model, eval_env, schema, episodes=3, deterministic=True):\n",
    "    \"\"\"Deterministic eval that returns actions/rewards and per-step observation series for plots.\"\"\"\n",
    "    # unwrap to CityLearnEnv (inline to avoid external dependency order)\n",
    "    def _get_base_env(env):\n",
    "        cur, seen = env, set()\n",
    "        while cur is not None and id(cur) not in seen:\n",
    "            seen.add(id(cur))\n",
    "            if isinstance(cur, CityLearnEnv):\n",
    "                return cur\n",
    "            cur = getattr(cur, \"env\", getattr(cur, \"unwrapped\", None))\n",
    "        raise RuntimeError(\"CityLearnEnv not found inside wrappers.\")\n",
    "\n",
    "    base = _get_base_env(eval_env)\n",
    "\n",
    "    # Building index (use Building_1 if present)\n",
    "    bld_names = [b.name for b in base.buildings]\n",
    "    building_name = 'Building_1' if 'Building_1' in bld_names else bld_names[0]\n",
    "    b_idx = bld_names.index(building_name)\n",
    "\n",
    "    # Observation indices for requested building\n",
    "    obs_names = getattr(base, 'observation_names', None)\n",
    "    if obs_names is None:\n",
    "        raise AttributeError(\"CityLearnEnv has no 'observation_names'.\")\n",
    "    obs_b = obs_names[b_idx]\n",
    "    name_to_idx = {n: i for i, n in enumerate(obs_b)}\n",
    "    i_net = name_to_idx.get('net_electricity_consumption')\n",
    "    if i_net is None:\n",
    "        i_net = name_to_idx.get('net_electricity_consumption_without_storage')\n",
    "    i_nsl   = name_to_idx.get('non_shiftable_load')\n",
    "    i_price = name_to_idx.get('electricity_pricing')\n",
    "    i_solar = name_to_idx.get('solar_generation')\n",
    "\n",
    "    ep_lengths, actions_disc_list, step_rewards_all = [], [], []\n",
    "    ep_action_fracs, ep_rewards_list = [], []\n",
    "    ep_net_load, ep_non_shiftable_load, ep_price, ep_solar_generation = [], [], [], []\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = eval_env.reset()\n",
    "        done = False\n",
    "\n",
    "        ep_actions, ep_fracs, ep_rewards = [], [], []\n",
    "        ep_net, ep_nsl, ep_prc, ep_sol = [], [], [], []\n",
    "\n",
    "        while not done:\n",
    "            act_disc, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, r, terminated, truncated, _ = eval_env.step(act_disc)\n",
    "            done = bool(terminated or truncated)\n",
    "\n",
    "            a_id = int(act_disc)\n",
    "            ep_actions.append(a_id)\n",
    "            ep_fracs.append(float(INT_TO_FRAC[a_id]))\n",
    "            ep_rewards.append(float(r))\n",
    "\n",
    "            raw = base.observations[b_idx]\n",
    "            ep_net.append(float(raw[i_net]) if i_net is not None else np.nan)\n",
    "            ep_nsl.append(float(raw[i_nsl]) if i_nsl is not None else np.nan)\n",
    "            ep_prc.append(float(raw[i_price]) if i_price is not None else np.nan)\n",
    "            ep_sol.append(float(raw[i_solar]) if i_solar is not None else np.nan)\n",
    "\n",
    "        ep_lengths.append(len(ep_rewards))\n",
    "        actions_disc_list.append(np.array(ep_actions, dtype=int))\n",
    "        step_rewards_all.extend(ep_rewards)\n",
    "        ep_action_fracs.append(np.array(ep_fracs, dtype=float))\n",
    "        ep_rewards_list.append(np.array(ep_rewards, dtype=float))\n",
    "        ep_net_load.append(np.array(ep_net, dtype=float))\n",
    "        ep_non_shiftable_load.append(np.array(ep_nsl, dtype=float))\n",
    "        ep_price.append(np.array(ep_prc, dtype=float))\n",
    "        ep_solar_generation.append(np.array(ep_sol, dtype=float))\n",
    "\n",
    "    # Pricing file info (kept for compatibility)\n",
    "    price_file = schema['buildings'][building_name]['pricing']\n",
    "    price_path = os.path.join(ROOT_DIR, price_file)\n",
    "    prc_df = pd.read_csv(price_path)\n",
    "    T = len(prc_df)\n",
    "\n",
    "    return {\n",
    "        'ep_lengths': np.array(ep_lengths, dtype=int),\n",
    "        'actions_disc_list': actions_disc_list,\n",
    "        'step_rewards': np.array(step_rewards_all, dtype=float),\n",
    "\n",
    "        # New per-episode, per-step series:\n",
    "        'ep_action_fracs': ep_action_fracs,\n",
    "        'ep_rewards_list': ep_rewards_list,\n",
    "        'ep_net_load': ep_net_load,\n",
    "        'ep_non_shiftable_load': ep_non_shiftable_load,\n",
    "        'ep_price': ep_price,\n",
    "        'ep_solar_generation': ep_solar_generation,\n",
    "\n",
    "        # Meta/compat fields:\n",
    "        'price_df': prc_df,\n",
    "        'episode_len': T,\n",
    "        'building_name': building_name,\n",
    "    }\n",
    "\n",
    "# Run eval and store results\n",
    "eval_results = eval_dqn(model, eval_env, schema_eval, episodes=10, deterministic=True)\n",
    "print('Eval episodes:', len(eval_results['ep_lengths']), 'total steps:', len(eval_results['step_rewards']))\n",
    "\n",
    "# Save eval results\n",
    "with open(EVAL_FILE, \"wb\") as f:\n",
    "    pickle.dump(eval_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5faa2f",
   "metadata": {},
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bceb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 2390363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/cj9272/.local/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/home/iai/cj9272/.local/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/home/iai/cj9272/.local/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-09-16 00:05:41,646] Using an existing study with name 'dqn_citylearn' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study ready: dqn_citylearn sqlite:////hkfs/home/haicore/iai/cj9272/artifacts/optuna_dqn.db?timeout=120 worker: 0\n"
     ]
    }
   ],
   "source": [
    "# Optuna objective for DQN on CityLearn (single building, same wrappers)\n",
    "import os, copy, json\n",
    "import numpy as np\n",
    "import optuna\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "ART_DIR = os.path.join(os.getcwd(), \"artifacts\")\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "#STORAGE_URL = f\"sqlite:///{os.path.join(ART_DIR, 'optuna_dqn.db')}\"\n",
    "STORAGE_URL = f\"sqlite:///{os.path.join(ART_DIR, 'optuna_dqn.db')}?timeout=120\"\n",
    "STUDY_NAME  = \"dqn_citylearn\"\n",
    "\n",
    "def make_env_one_building(schema_src, building_name=\"Building_1\", n_bins=5, monitor=False):\n",
    "    schema_1b = copy.deepcopy(schema_src)\n",
    "    schema_1b['buildings'] = {k: v for k, v in schema_src['buildings'].items() if k == building_name}\n",
    "    if not schema_1b['buildings']:\n",
    "        raise RuntimeError(f\"{building_name} not found in schema['buildings']\")\n",
    "    env = CityLearnEnv(schema_1b, central_agent=True)\n",
    "    env = NormalizedObservationWrapper(env)\n",
    "    env = StableBaselines3Wrapper(env)\n",
    "    env = DiscretizeActionWrapper(env, n_bins=n_bins)\n",
    "    if monitor:\n",
    "        env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "def evaluate_mean_reward(model, env, episodes=2, deterministic=True):\n",
    "    rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        ep_ret = 0.0\n",
    "        while not done:\n",
    "            act, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, r, terminated, truncated, _ = env.step(act)\n",
    "            ep_ret += float(r)\n",
    "            done = bool(terminated or truncated)\n",
    "        rewards.append(ep_ret)\n",
    "    return float(np.mean(rewards))\n",
    "\n",
    "class OptunaEvalPruningCallback:\n",
    "    def __init__(self, trial, model, eval_env, eval_every_steps, eval_episodes=2):\n",
    "        self.trial = trial\n",
    "        self.model = model\n",
    "        self.eval_env = eval_env\n",
    "        self.eval_every_steps = int(eval_every_steps)\n",
    "        self.eval_episodes = int(eval_episodes)\n",
    "        self._last_step = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def __call__(self, locals_, globals_):\n",
    "        # Called by SB3 when using callback= in learn (old-style callable)\n",
    "        step = int(locals_.get(\"self\").num_timesteps)\n",
    "        if step - self._last_step >= self.eval_every_steps:\n",
    "            self._last_step = step\n",
    "            mean_r = evaluate_mean_reward(self.model, self.eval_env, episodes=self.eval_episodes, deterministic=True)\n",
    "            self.trial.report(mean_r, step=step)\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False  # stop training\n",
    "        return True\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Search space\n",
    "    lr      = trial.suggest_float(\"learning_rate\", 1e-5, 3e-3, log=True)\n",
    "    gamma   = trial.suggest_float(\"gamma\", 0.90, 0.9999)\n",
    "    buffer  = trial.suggest_int(\"buffer_size\", 50_000, 200_000, step=25_000)\n",
    "    batch   = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    #tau     = trial.suggest_float(\"tau\", 0.005, 1.0, log=True)\n",
    "    #tgt_upd = trial.suggest_int(\"target_update_interval\", 250, 5000, step=250)\n",
    "    train_f = trial.suggest_int(\"train_freq\", 1, 8)\n",
    "    grad_st = trial.suggest_int(\"gradient_steps\", 1, 4)\n",
    "    expl_fr = trial.suggest_float(\"exploration_fraction\", 0.05, 0.4)\n",
    "    expl_fin= trial.suggest_float(\"exploration_final_eps\", 0.01, 0.1)\n",
    "    #starts  = trial.suggest_int(\"learning_starts\", 500, 5000, step=500)\n",
    "    #arch_key = trial.suggest_categorical(\"net_arch\", [\"256x256\", \"256x256x256\", \"512x512\"])\n",
    "    #arch    = tuple(int(x) for x in arch_key.split(\"x\"))\n",
    "    \t\n",
    "    # Build train/eval envs\n",
    "    train_env = make_env_one_building(schema, building_name=\"Building_1\", n_bins=5, monitor=True)\n",
    "    eval_env  = make_env_one_building(schema, building_name=\"Building_1\", n_bins=5, monitor=False)\n",
    "    T = train_env.unwrapped.time_steps\n",
    "\n",
    "    # Episodes per trial (keep small for speed)\n",
    "    episodes_per_trial = 3 # increase to 5-10\n",
    "    total_steps = episodes_per_trial * T\n",
    "\n",
    "    model = DQN(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=train_env,\n",
    "        seed=0,\n",
    "        learning_rate=lr,\n",
    "        gamma=gamma,\n",
    "        buffer_size=buffer,\n",
    "        batch_size=batch,\n",
    "        exploration_fraction=expl_fr,\n",
    "        exploration_final_eps=expl_fin,\n",
    "        train_freq=train_f,\n",
    "        gradient_steps=grad_st,\n",
    "        verbose=0,\n",
    "        policy_kwargs=dict(net_arch=[512, 512], activation_fn=th.nn.ReLU),\n",
    "        device=\"auto\",\n",
    "    )\n",
    "\n",
    "    # Eval + pruning during training\n",
    "    cb = OptunaEvalPruningCallback(trial, model, eval_env, eval_every_steps=T//2, eval_episodes=2) # increase to 3\n",
    "    try:\n",
    "        model.learn(total_timesteps=total_steps, callback=cb)\n",
    "        if cb.is_pruned:\n",
    "            raise optuna.TrialPruned()\n",
    "    finally:\n",
    "        # Ensure envs are closed\n",
    "        try: train_env.close()\n",
    "        except: pass\n",
    "        try: eval_env.close()\n",
    "        except: pass\n",
    "\n",
    "    # Final score\n",
    "    eval_env = make_env_one_building(schema, building_name=\"Building_1\", n_bins=5, monitor=False)\n",
    "    score = evaluate_mean_reward(model, eval_env, episodes=3, deterministic=True)\n",
    "    eval_env.close()\n",
    "\n",
    "    # Save best-so-far model snapshot\n",
    "    trial.set_user_attr(\"final_mean_reward\", score)\n",
    "    return score\n",
    "\n",
    "print(f\"PID: {os.getpid()}\")\n",
    "\n",
    "# Create/continue a study\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    direction=\"maximize\",\n",
    "    storage=STORAGE_URL,\n",
    "    load_if_exists=True,\n",
    "    sampler=TPESampler(seed=0 + WORKER_ID, multivariate=True, group=True, constant_liar=True),  # vary per worker\n",
    "    #sampler=RandomSampler(seed=0 + WORKER_ID),  # vary per worker\n",
    "    #pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1), # NopPruner()\n",
    "    pruner=SuccessiveHalvingPruner(min_resource=1, reduction_factor=3, min_early_stopping_rate=0),\n",
    ")\n",
    "print(\"Study ready:\", STUDY_NAME, STORAGE_URL, \"worker:\", WORKER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameter optimization\n",
    "\n",
    "#N_TRIALS = 30  # increase as needed\n",
    "N_TRIALS = None  # let timeout drive the run\n",
    "TIMEOUT_SECONDS = int((3*3600 + 40*60) / 2)  # 6600 seconds per worker\n",
    "study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT_SECONDS, gc_after_trial=True, catch=(Exception,))\n",
    "print(\"Done. Trials now:\", len(study.trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d7ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial35: 35 PRUNED {'learning_rate': 0.0002752350841138598, 'gamma': 0.9851293040985031, 'buffer_size': 125000, 'batch_size': 256, 'train_freq': 5, 'gradient_steps': 4, 'exploration_fraction': 0.18063198209981218, 'exploration_final_eps': 0.05601773593918628} -259.5954436971694\n",
      "n_completed: 7\n",
      "best_completed: 9 -263.07821044774175 {'learning_rate': 1.1131267357743944e-05, 'gamma': 0.9617017861578802, 'buffer_size': 150000, 'batch_size': 64, 'tau': 0.05065165487856718, 'target_update_interval': 3500, 'train_freq': 1, 'gradient_steps': 3, 'exploration_fraction': 0.2847232543663558, 'exploration_final_eps': 0.028934430496645687, 'learning_starts': 1000, 'net_arch': [512, 512]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/cj9272/.local/lib/python3.11/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256, 256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/home/iai/cj9272/.local/lib/python3.11/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256, 256, 256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/home/iai/cj9272/.local/lib/python3.11/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [512, 512] which is of type list.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import os, optuna\n",
    "DB = os.path.abspath(\"examples/artifacts/optuna_dqn.db\")\n",
    "study = optuna.load_study(study_name=STUDY_NAME, storage=STORAGE_URL)\n",
    "t35 = next((t for t in study.trials if t.number == 35), None)\n",
    "print(\"trial35:\", t35.number if t35 else None, t35.state.name if t35 else None, t35.params if t35 else None, t35.value if t35 else None)\n",
    "\n",
    "completed = [t for t in study.trials if t.state.name == \"COMPLETE\"]\n",
    "print(\"n_completed:\", len(completed))\n",
    "if completed:\n",
    "    best_completed = max(completed, key=lambda t: t.value)\n",
    "    print(\"best_completed:\", best_completed.number, best_completed.value, best_completed.params)\n",
    "else:\n",
    "    print(\"No complete trials found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68f93e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial number: 9\n",
      "Best value (objective): -263.07821044774175\n",
      "Best params:\n",
      "  learning_rate: 1.1131267357743944e-05\n",
      "  gamma: 0.9617017861578802\n",
      "  buffer_size: 150000\n",
      "  batch_size: 64\n",
      "  tau: 0.05065165487856718\n",
      "  target_update_interval: 3500\n",
      "  train_freq: 1\n",
      "  gradient_steps: 3\n",
      "  exploration_fraction: 0.2847232543663558\n",
      "  exploration_final_eps: 0.028934430496645687\n",
      "  learning_starts: 1000\n",
      "  net_arch: [512, 512]\n",
      "\n",
      "Top 7 trials (number, value):\n",
      "  #9\t-263.07821044774175\t{'learning_rate': 1.1131267357743944e-05, 'gamma': 0.9617017861578802, 'buffer_size': 150000, 'batch_size': 64, 'tau': 0.05065165487856718, 'target_update_interval': 3500, 'train_freq': 1, 'gradient_steps': 3, 'exploration_fraction': 0.2847232543663558, 'exploration_final_eps': 0.028934430496645687, 'learning_starts': 1000, 'net_arch': [512, 512]}\n",
      "  #4\t-264.1950055838423\t{'learning_rate': 0.0002288113668475521, 'gamma': 0.9714474177006047, 'buffer_size': 150000, 'batch_size': 128, 'tau': 0.5635940875693888, 'target_update_interval': 5000, 'train_freq': 4, 'gradient_steps': 4, 'exploration_fraction': 0.23511322191351658, 'exploration_final_eps': 0.061124010498453916, 'learning_starts': 5000, 'net_arch': [256, 256, 256]}\n",
      "  #7\t-264.1950055838423\t{'learning_rate': 0.0002288113668475521, 'gamma': 0.9714474177006047, 'buffer_size': 150000, 'batch_size': 128, 'tau': 0.5635940875693888, 'target_update_interval': 5000, 'train_freq': 4, 'gradient_steps': 4, 'exploration_fraction': 0.23511322191351658, 'exploration_final_eps': 0.061124010498453916, 'learning_starts': 5000, 'net_arch': [256, 256, 256]}\n",
      "  #11\t-264.41574065017556\t{'learning_rate': 0.0002288113668475521, 'gamma': 0.9714474177006047, 'buffer_size': 150000, 'batch_size': 128, 'train_freq': 8, 'gradient_steps': 4, 'exploration_fraction': 0.18420453158902222, 'exploration_final_eps': 0.08125525342743982}\n",
      "  #0\t-264.9435168108443\t{'learning_rate': 7.542099442919726e-05, 'gamma': 0.9446866602121069, 'buffer_size': 175000, 'batch_size': 32, 'tau': 0.0770007551262532, 'target_update_interval': 2000, 'train_freq': 4, 'gradient_steps': 3, 'exploration_fraction': 0.39319303308523335, 'exploration_final_eps': 0.016055424647748635, 'learning_starts': 2500, 'net_arch': [256, 256]}\n",
      "  #5\t-267.4419971243363\t{'learning_rate': 0.0011547828262799351, 'gamma': 0.9777378594198901, 'buffer_size': 200000, 'batch_size': 32, 'tau': 0.009356706482439718, 'target_update_interval': 3250, 'train_freq': 2, 'gradient_steps': 4, 'exploration_fraction': 0.23264691261252513, 'exploration_final_eps': 0.04731957459914713, 'learning_starts': 1500, 'net_arch': [256, 256]}\n",
      "  #8\t-267.4419971243363\t{'learning_rate': 0.0011547828262799351, 'gamma': 0.9777378594198901, 'buffer_size': 200000, 'batch_size': 32, 'tau': 0.009356706482439718, 'target_update_interval': 3250, 'train_freq': 2, 'gradient_steps': 4, 'exploration_fraction': 0.23264691261252513, 'exploration_final_eps': 0.04731957459914713, 'learning_starts': 1500, 'net_arch': [256, 256]}\n",
      "\n",
      "Parameter summary (unique values seen):\n",
      "  batch_size: 4 unique (examples: [32, 256, 64, 128])\n",
      "  buffer_size: 7 unique (examples: [200000, 75000, 100000, 125000, 50000, 150000])\n",
      "  exploration_final_eps: 87 unique (examples: [0.048376699632846076, 0.019290346424862825, 0.028934430496645687, 0.020729309646746026, 0.046592449345099325, 0.06053031653922925])\n",
      "  exploration_fraction: 87 unique (examples: [0.39319303308523335, 0.23511322191351658, 0.2847232543663558, 0.3138735548796754, 0.3002175017314537, 0.31296687755440566])\n",
      "  gamma: 86 unique (examples: [0.9446866602121069, 0.9714474177006047, 0.9223334999986974, 0.9779748647110169, 0.9557343277273349, 0.9331995980416004])\n",
      "  gradient_steps: 4 unique (examples: [1, 2, 3, 4])\n",
      "  learning_rate: 86 unique (examples: [0.00022398653010258357, 6.61341188581449e-05, 1.8911506669555177e-05, 0.0008186917241528364, 0.00014038840015940341, 4.928498968538067e-05])\n",
      "  learning_starts: 4 unique (examples: [5000, 1000, 1500, 2500])\n",
      "  net_arch: 3 unique (examples: [(512, 512), (256, 256), (256, 256, 256)])\n",
      "  target_update_interval: 4 unique (examples: [2000, 3250, 3500, 5000])\n",
      "  tau: 4 unique (examples: [0.0770007551262532, 0.5635940875693888, 0.05065165487856718, 0.009356706482439718])\n",
      "  train_freq: 8 unique (examples: [1, 2, 3, 4, 5, 6])\n",
      "\n",
      "Saved best params to: /hkfs/home/haicore/iai/cj9272/artifacts/best_params_dqn_citylearn.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import optuna\n",
    "from collections import defaultdict\n",
    "\n",
    "ART_DIR = os.path.join(os.getcwd(), \"artifacts\")\n",
    "STORAGE_URL = f\"sqlite:///{os.path.join(ART_DIR, 'optuna_dqn.db')}?timeout=120\"\n",
    "STUDY_NAME = \"dqn_citylearn\"\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(study_name=STUDY_NAME, storage=STORAGE_URL)\n",
    "except Exception as e:\n",
    "    print(\"Study could not be loaded:\", e)\n",
    "    raise\n",
    "\n",
    "if not study.trials:\n",
    "    print(\"Keine Trials in der Studie gefunden.\")\n",
    "else:\n",
    "    best = study.best_trial\n",
    "    print(\"Best trial number:\", best.number)\n",
    "    print(\"Best value (objective):\", best.value)\n",
    "    print(\"Best params:\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    # Top-K completed trials (by objective value)\n",
    "    top_k = 10\n",
    "    completed = [t for t in study.trials if t.value is not None and t.state.name == \"COMPLETE\"]\n",
    "    completed_sorted = sorted(completed, key=lambda t: t.value, reverse=True)[:top_k]\n",
    "    print(f\"\\nTop {min(top_k, len(completed_sorted))} trials (number, value):\")\n",
    "    for t in completed_sorted:\n",
    "        print(f\"  #{t.number}\\t{t.value}\\t{t.params}\")\n",
    "\n",
    "    # Per-parameter summary (unique values seen)\n",
    "    param_vals = defaultdict(set)\n",
    "\n",
    "    def _to_hashable(val):\n",
    "        \"\"\"Return a hashable representation for val (keep numbers/strings as-is).\"\"\"\n",
    "        try:\n",
    "            hash(val)\n",
    "            return val\n",
    "        except TypeError:\n",
    "            # lists/sets -> tuple, dict -> json string (sorted keys), other -> str\n",
    "            if isinstance(val, (list, set, tuple)):\n",
    "                return tuple(_to_hashable(v) for v in val)\n",
    "            if isinstance(val, dict):\n",
    "                return json.dumps(val, sort_keys=True, default=str)\n",
    "            return json.dumps(val, sort_keys=True, default=str)\n",
    "\n",
    "    for t in study.trials:\n",
    "        for k, v in t.params.items():\n",
    "            param_vals[k].add(_to_hashable(v))\n",
    "\n",
    "    print(\"\\nParameter summary (unique values seen):\")\n",
    "    for k in sorted(param_vals.keys()):\n",
    "        vals = list(param_vals[k])\n",
    "        # pretty-print JSON-like strings back to python objects when possible for readability\n",
    "        def _pretty(v):\n",
    "            if isinstance(v, str):\n",
    "                try:\n",
    "                    return json.loads(v)\n",
    "                except Exception:\n",
    "                    return v\n",
    "            return v\n",
    "        examples = [_pretty(x) for x in vals[:6]]\n",
    "        print(f\"  {k}: {len(vals)} unique (examples: {examples})\")\n",
    "\n",
    "    # Save best params to artifacts\n",
    "    os.makedirs(ART_DIR, exist_ok=True)\n",
    "    out_path = os.path.join(ART_DIR, f\"best_params_{STUDY_NAME}.json\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump({\"trial\": int(best.number), \"value\": float(best.value), \"params\": best.params}, f, indent=2)\n",
    "    print(\"\\nSaved best params to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain candidate to confirm and produce final models\n",
    "import time, pathlib, numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "# Candidate hyperparams (trial 35)\n",
    "trial35_params = {\n",
    "    \"learning_rate\": 0.0002752350841138598,\n",
    "    \"gamma\": 0.9851293040985031,\n",
    "    \"buffer_size\": 125000,\n",
    "    \"batch_size\": 256,\n",
    "    \"train_freq\": 5,\n",
    "    \"gradient_steps\": 4,\n",
    "    \"exploration_fraction\": 0.18063198209981218,\n",
    "    \"exploration_final_eps\": 0.05601773593918628,\n",
    "    # safe defaults (optional)\n",
    "    \"tau\": 0.05065165487856718,\n",
    "    \"target_update_interval\": 3500,\n",
    "    \"learning_starts\": 1000,\n",
    "    \"net_arch\": [512, 512],\n",
    "}\n",
    "\n",
    "def _build_kwargs(p, seed):\n",
    "    kw = dict(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=None,  # set per-run\n",
    "        seed=int(seed),\n",
    "        learning_rate=float(p[\"learning_rate\"]),\n",
    "        gamma=float(p.get(\"gamma\", 0.99)),\n",
    "        buffer_size=int(p.get(\"buffer_size\", 150000)),\n",
    "        batch_size=int(p.get(\"batch_size\", 64)),\n",
    "        train_freq=int(p.get(\"train_freq\", 1)),\n",
    "        gradient_steps=int(p.get(\"gradient_steps\", 1)),\n",
    "        exploration_fraction=float(p.get(\"exploration_fraction\", 0.1)),\n",
    "        exploration_final_eps=float(p.get(\"exploration_final_eps\", 0.02)),\n",
    "        tau=float(p.get(\"tau\", 1.0)),\n",
    "        target_update_interval=int(p.get(\"target_update_interval\", 1000)),\n",
    "        learning_starts=int(p.get(\"learning_starts\", 1000)),\n",
    "        verbose=0,\n",
    "        device=\"cuda\",\n",
    "        policy_kwargs=dict(net_arch=p.get(\"net_arch\", [512,512]), activation_fn=th.nn.ReLU),\n",
    "    )\n",
    "    return kw\n",
    "\n",
    "def final_retrain(params, seeds=(0,1), episodes_per_run=50, save_dir=\"final_models_trial35\"):\n",
    "    save_dir = pathlib.Path(save_dir); save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    scores = []\n",
    "    for s in seeds:\n",
    "        print(f\"Seed {s} — building envs\")\n",
    "        train_env = make_env_one_building(schema, building_name=\"Building_1\", n_bins=5, monitor=True)\n",
    "        eval_env  = make_env_one_building(schema, building_name=\"Building_1\", n_bins=5, monitor=False)\n",
    "        T = train_env.unwrapped.time_steps\n",
    "        total_steps = int(episodes_per_run * T)\n",
    "        kwargs = _build_kwargs(params, seed=s)\n",
    "        kwargs[\"env\"] = train_env\n",
    "        model = DQN(**kwargs)\n",
    "        t0 = time.time()\n",
    "        model.learn(total_timesteps=total_steps)\n",
    "        dur = time.time() - t0\n",
    "        score = evaluate_mean_reward(model, eval_env, episodes=10, deterministic=True)\n",
    "        fname = save_dir / f\"trial35_seed{s}.zip\"\n",
    "        model.save(str(fname))\n",
    "        print(f\"Done seed {s}: eval mean={score:.3f} train_time={dur:.1f}s saved->{fname}\")\n",
    "        try: train_env.close(); eval_env.close()\n",
    "        except: pass\n",
    "        scores.append(float(score))\n",
    "    print(\"Final results:\", scores, \"mean=\", np.mean(scores), \"std=\", np.std(scores))\n",
    "    return scores\n",
    "\n",
    "# Run: increase episodes_per_run as needed (50 is reasonable for confirmation)\n",
    "results = final_retrain(trial35_params, seeds=(0,1), episodes_per_run=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bb38a",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "815990fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/hkfs/home/haicore/iai/cj9272/logs/dqn/dqn_eval_01.pkl not found. Run eval_dqn(...) and save eval_results first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     64\u001b[39m     df = pd.DataFrame({\n\u001b[32m     65\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mt\u001b[39m\u001b[33m'\u001b[39m: np.arange(L, dtype=\u001b[38;5;28mint\u001b[39m),\n\u001b[32m     66\u001b[39m         \u001b[33m'\u001b[39m\u001b[33maction_id\u001b[39m\u001b[33m'\u001b[39m: a_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msolar_generation\u001b[39m\u001b[33m'\u001b[39m: solar,\n\u001b[32m     73\u001b[39m     })\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df, er.get(\u001b[33m'\u001b[39m\u001b[33mbuilding_name\u001b[39m\u001b[33m'\u001b[39m, building_name)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m er = \u001b[43m_ensure_eval_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m actions_disc = np.concatenate(er[\u001b[33m'\u001b[39m\u001b[33mactions_disc_list\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m0\u001b[39m)\n\u001b[32m     78\u001b[39m actions_frac = pd.Series(actions_disc).map({\u001b[32m0\u001b[39m:-\u001b[32m1.0\u001b[39m, \u001b[32m1\u001b[39m:-\u001b[32m0.5\u001b[39m, \u001b[32m2\u001b[39m:\u001b[32m0.0\u001b[39m, \u001b[32m3\u001b[39m:\u001b[32m0.5\u001b[39m, \u001b[32m4\u001b[39m:\u001b[32m1.0\u001b[39m}).to_numpy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36m_ensure_eval_results\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded eval_results missing keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_results\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found. Run eval_dqn(...) and save eval_results first.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: /hkfs/home/haicore/iai/cj9272/logs/dqn/dqn_eval_01.pkl not found. Run eval_dqn(...) and save eval_results first."
     ]
    }
   ],
   "source": [
    "import os, copy, pickle\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "# ------------- Helpers -------------\n",
    "def unwrap_to_citylearn(env):\n",
    "    cur, seen = env, set()\n",
    "    while cur is not None and id(cur) not in seen:\n",
    "        seen.add(id(cur))\n",
    "        if isinstance(cur, CityLearnEnv):\n",
    "            return cur\n",
    "        cur = getattr(cur, \"env\", getattr(cur, \"unwrapped\", None))\n",
    "    raise RuntimeError(\"CityLearnEnv not found inside wrappers.\")\n",
    "\n",
    "# Use cached eval_results if available, else load from eval file\n",
    "def _ensure_eval_results(path=EVAL_FILE):\n",
    "    \"\"\"Return cached eval_results if present; else load from file. No quick-eval fallback.\"\"\"\n",
    "    global eval_results\n",
    "    \"\"\"\n",
    "    if 'eval_results' in globals():\n",
    "        print(\"Using cached eval_results.\")\n",
    "        return eval_results\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            eval_results = pickle.load(f)\n",
    "            print(f\"Eval results loaded from {path}.\")\n",
    "        # Sanity check\n",
    "        required = {'ep_lengths','actions_disc_list','step_rewards','price_df','episode_len','building_name'}\n",
    "        missing = required - set(eval_results.keys())\n",
    "        if missing:\n",
    "            raise ValueError(f\"Loaded eval_results missing keys: {missing}\")\n",
    "        return eval_results\n",
    "    raise FileNotFoundError(f\"{path} not found. Run eval_dqn(...) and save eval_results first.\")\n",
    "\n",
    "def capture_ep_series_dqn(model, env, building_name=\"Building_1\", deterministic=True, max_steps=None, episode_idx=0):\n",
    "    \"\"\"Build per-step DataFrame from saved eval_results; no env stepping or model usage.\"\"\"\n",
    "    er = _ensure_eval_results()\n",
    "    needed = ['ep_action_fracs','ep_rewards_list','ep_net_load','ep_non_shiftable_load','ep_price','ep_solar_generation','actions_disc_list','building_name']\n",
    "    missing = [k for k in needed if k not in er]\n",
    "    if missing:\n",
    "        raise ValueError(f\"eval_results missing keys: {missing}. Re-run eval_dqn to regenerate with per-step series.\")\n",
    "    n_eps = len(er['ep_rewards_list'])\n",
    "    if not (0 <= episode_idx < n_eps):\n",
    "        raise IndexError(f\"episode_idx {episode_idx} out of range 0..{n_eps-1}\")\n",
    "\n",
    "    a_id   = np.asarray(er['actions_disc_list'][episode_idx], dtype=int)\n",
    "    a_frac = np.asarray(er['ep_action_fracs'][episode_idx], dtype=float)\n",
    "    rew    = np.asarray(er['ep_rewards_list'][episode_idx], dtype=float)\n",
    "    net    = np.asarray(er['ep_net_load'][episode_idx], dtype=float)\n",
    "    nsl    = np.asarray(er['ep_non_shiftable_load'][episode_idx], dtype=float)\n",
    "    price  = np.asarray(er['ep_price'][episode_idx], dtype=float)\n",
    "    solar  = np.asarray(er['ep_solar_generation'][episode_idx], dtype=float)\n",
    "\n",
    "    L = len(rew)\n",
    "    if max_steps is not None:\n",
    "        L = min(L, int(max_steps))\n",
    "        a_id, a_frac, rew, net, nsl, price, solar = a_id[:L], a_frac[:L], rew[:L], net[:L], nsl[:L], price[:L], solar[:L]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        't': np.arange(L, dtype=int),\n",
    "        'action_id': a_id,\n",
    "        'action_frac': a_frac,\n",
    "        'reward': rew,\n",
    "        'net_load': net,\n",
    "        'non_shiftable_load': nsl,\n",
    "        'price': price,\n",
    "        'solar_generation': solar,\n",
    "    })\n",
    "    return df, er.get('building_name', building_name)\n",
    "\n",
    "er = _ensure_eval_results()\n",
    "actions_disc = np.concatenate(er['actions_disc_list'], axis=0)\n",
    "actions_frac = pd.Series(actions_disc).map({0:-1.0, 1:-0.5, 2:0.0, 3:0.5, 4:1.0}).to_numpy()\n",
    "hour_index = np.arange(len(actions_frac))\n",
    "building_name = er['building_name']\n",
    "\n",
    "# Plot 1: Actions over time (raw + MA)\n",
    "window = 500\n",
    "act_ma = pd.Series(actions_frac).rolling(window, min_periods=1).mean().to_numpy()\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.scatter(hour_index, actions_frac, s=5, alpha=0.35, label='raw')\n",
    "plt.plot(hour_index, act_ma, color='C2', lw=2, label=f'ma {window}')\n",
    "plt.title(f'DQN Eval Actions over time (Raw + MA) - {building_name}')\n",
    "plt.xlabel('Timestep'); plt.ylabel('Action [-1..1]'); plt.grid(True); plt.legend(loc='upper right')\n",
    "plt.yticks(INT_TO_FRAC.tolist(), ACTION_LABELS)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Plot 2: Action Distribution (5-bin)\n",
    "plt.figure(figsize=(4,3))\n",
    "counts = pd.Series(actions_disc).value_counts().reindex(range(5)).fillna(0).astype(int)\n",
    "ax = counts.plot(kind='bar', color=['C0','C1','C2','C3','C4'])\n",
    "ax.set_xticklabels(ACTION_LABELS, rotation=45, ha='right')\n",
    "total = counts.sum()\n",
    "ax.bar_label(ax.containers[0], labels=[f'{int(v)}\\n({v/total:.1%})' for v in counts.values])\n",
    "ax.set_ylim(0, counts.max()*1.5)\n",
    "plt.ylabel('Count'); plt.title('Action Distribution'); plt.tight_layout(); plt.show()\n",
    "\n",
    "def add_top_legend(ax_left, ax_right=None, ncol=3, y=1.50, top=0.84, loc='upper center', frameon=False):\n",
    "    \"\"\"Place a combined legend above the plot using lines from one or two axes.\"\"\"\n",
    "    handles = []\n",
    "    for ax in (ax_left, ax_right):\n",
    "        if ax is None:\n",
    "            continue\n",
    "        handles.extend(ax.get_lines())\n",
    "    labels = [h.get_label() for h in handles]\n",
    "    legend = ax_left.legend(handles, labels, loc=loc, bbox_to_anchor=(0.5, y), ncol=ncol, frameon=frameon)\n",
    "    if top is not None:\n",
    "        plt.subplots_adjust(top=top)\n",
    "    return legend\n",
    "\n",
    "def plot_first_30_steps_actions_vs_loads_dqn(model, env, building_name=\"Building_1\", deterministic=True):\n",
    "    df30, bname = capture_ep_series_dqn(model, env, building_name, deterministic=deterministic, max_steps=30)\n",
    "\n",
    "    t = df30['t'].to_numpy()\n",
    "    net = df30['net_load'].to_numpy()\n",
    "    nsl = df30['non_shiftable_load'].to_numpy()\n",
    "    act = df30['action_frac'].to_numpy()\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10.5, 3.6))\n",
    "    ax1.plot(t, net, color='C4', marker='o', label='Net Load (with storage)')\n",
    "    ax1.plot(t, nsl, color='C1', ls='--', marker='x', label='Non-shiftable Load (baseline)')\n",
    "    ax1.set_xlabel('Timestep')\n",
    "    ax1.set_ylabel('Load')\n",
    "    ax1.set_xticks(t[::2])\n",
    "    ax1.set_ylim(-2, 4)  # enforce requested load range\n",
    "    ax1.yaxis.set_major_locator(MultipleLocator(2))  # enforce ticks every 2 units\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.step(t, act, where='mid', color='C0', label='Action')\n",
    "    ax2.set_ylabel('Action')\n",
    "    ax2.set_ylim(-1.1, 1.1)\n",
    "    ax2.set_yticks(INT_TO_FRAC.tolist())\n",
    "    ax2.set_yticklabels(ACTION_LABELS)\n",
    "    add_top_legend(ax1, ax2)\n",
    "    plt.title(f'DQN — first 30 steps — {bname} (deterministic={deterministic})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_ep1_reward_vs_obs_dqn(model, env, building_name=\"Building_1\", deterministic=True, episode_idx=0):\n",
    "    \"\"\"Plot using stored eval_results only; no rollout or replay.\"\"\"\n",
    "    er = _ensure_eval_results()\n",
    "    req = ['ep_rewards_list','ep_price','ep_solar_generation','ep_net_load','building_name']\n",
    "    miss = [k for k in req if k not in er]\n",
    "    if miss:\n",
    "        raise ValueError(f\"eval_results missing keys: {miss}. Re-run eval_dqn to regenerate with per-step series.\")\n",
    "\n",
    "    n_eps = len(er['ep_rewards_list'])\n",
    "    if not (0 <= episode_idx < n_eps):\n",
    "        raise IndexError(f\"episode_idx {episode_idx} out of range 0..{n_eps-1}\")\n",
    "\n",
    "    rewards = np.asarray(er['ep_rewards_list'][episode_idx], dtype=float)\n",
    "    price   = np.asarray(er['ep_price'][episode_idx], dtype=float)\n",
    "    solar   = np.asarray(er['ep_solar_generation'][episode_idx], dtype=float)\n",
    "    net     = np.asarray(er['ep_net_load'][episode_idx], dtype=float)\n",
    "    t = np.arange(len(rewards))\n",
    "\n",
    "    window_reward = 24\n",
    "    window_x = 24\n",
    "    reward_ma = pd.Series(rewards).rolling(window_reward, min_periods=1).mean().to_numpy()\n",
    "    price_ma  = pd.Series(price).rolling(window_x, min_periods=1).mean().to_numpy()\n",
    "    solar_ma  = pd.Series(solar).rolling(window_x, min_periods=1).mean().to_numpy()\n",
    "    net_ma    = pd.Series(net).rolling(window_x, min_periods=1).mean().to_numpy()\n",
    "\n",
    "    # 4) Reward vs Net Load\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 3.5))\n",
    "    ax1.plot(t, reward_ma, color='C3', label=f'Reward MA (w={window_reward})')\n",
    "    ax1.set_xlabel('Timestep'); ax1.set_ylabel(f'Reward MA ({window_reward})', color='C3')\n",
    "    ax1.tick_params(axis='y', labelcolor='C3'); ax1.grid(True, axis='x', alpha=0.3)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, net_ma, color='C4', label=f'Net Load MA (w={window_x})')\n",
    "    ax2.set_ylabel('Net Electricity Consumption', color='C4'); ax2.tick_params(axis='y', labelcolor='C4')\n",
    "    add_top_legend(ax1, ax2)\n",
    "    ax1.set_title(f'DQN Episode {episode_idx+1} — Reward vs Net Load — {building_name}')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 5) Reward vs Electricity Price\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 3.5))\n",
    "    ax1.plot(t, reward_ma, color='C3', label=f'Reward MA (w={window_reward})')\n",
    "    ax1.set_xlabel('Timestep'); ax1.set_ylabel(f'Reward MA ({window_reward})', color='C3')\n",
    "    ax1.tick_params(axis='y', labelcolor='C3'); ax1.grid(True, axis='x', alpha=0.3)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, price_ma, color='C0', label=f'Price MA (w={window_x})')\n",
    "    ax2.set_ylabel('Electricity Price', color='C0'); ax2.tick_params(axis='y', labelcolor='C0')\n",
    "    add_top_legend(ax1, ax2)\n",
    "    ax1.set_title(f'DQN Episode {episode_idx+1} — Reward vs Electricity Price — {building_name}')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 6) Reward vs Solar Generation\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 3.5))\n",
    "    ax1.plot(t, reward_ma, color='C3', label=f'Reward MA (w={window_reward})')\n",
    "    ax1.set_xlabel('Timestep'); ax1.set_ylabel(f'Reward MA ({window_reward})', color='C3')\n",
    "    ax1.tick_params(axis='y', labelcolor='C3'); ax1.grid(True, axis='x', alpha=0.3)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, solar_ma, color='C2', label=f'Solar Gen MA (w={window_x})')\n",
    "    ax2.set_ylabel('Solar Generation', color='C2'); ax2.tick_params(axis='y', labelcolor='C2')\n",
    "    add_top_legend(ax1, ax2)\n",
    "    ax1.set_title(f'DQN Episode {episode_idx+1} — Reward vs Solar Generation — {building_name}')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "# ----- Plot 3: Actions vs Loads (first 30 steps) -----\n",
    "plot_first_30_steps_actions_vs_loads_dqn(model, eval_env, building_name=\"Building_1\", deterministic=False)\n",
    "\n",
    "\n",
    "# ----- Plot 4,5,6: Actions vs Observations(Net Load, Price, Solar Generation) - first episode -----\n",
    "plot_ep1_reward_vs_obs_dqn(model, eval_env, building_name=\"Building_1\", deterministic=False, episode_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71234d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2210 rows from /hkfs/home/haicore/iai/cj9272/train_steps.csv\n",
      "Fitting 5 folds for each of 2400 candidates, totalling 12000 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 12000 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4800 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1024, in fit\n    super()._fit(\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 252, in _fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2956, in validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1139, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(1325, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n\n--------------------------------------------------------------------------------\n7200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1024, in fit\n    super()._fit(\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 252, in _fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2956, in validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1139, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(1326, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     66\u001b[39m cv = StratifiedKFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# keeps class proportions similar in each fold\u001b[39;00m\n\u001b[32m     67\u001b[39m grid = GridSearchCV(\n\u001b[32m     68\u001b[39m     DecisionTreeClassifier(random_state=\u001b[32m0\u001b[39m),\n\u001b[32m     69\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     74\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest balanced_accuracy:\u001b[39m\u001b[33m\"\u001b[39m, grid.best_score_)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, grid.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1001\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    996\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    998\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m    999\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1004\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 12000 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4800 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1024, in fit\n    super()._fit(\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 252, in _fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2956, in validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1139, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(1325, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n\n--------------------------------------------------------------------------------\n7200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1024, in fit\n    super()._fit(\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 252, in _fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2956, in validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/software/all/jupyter/ai/2025-05-23/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1139, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(1326, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n"
     ]
    }
   ],
   "source": [
    "# ---- Explainability: Decision Tree (state -> action) ----\n",
    "# Trains a small DecisionTreeClassifier on (observation -> action) pairs from training logs.\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Load logged steps (x0..xN features, 'action' as label)\n",
    "def _load_policy_dataset(csv_path=\"train_steps.csv\"):\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded {len(df)} rows from {os.path.abspath(csv_path)}\")\n",
    "        return df\n",
    "    if 'train_callback' in globals() and hasattr(train_callback, 'df') and len(train_callback.df):\n",
    "        print(\"Using in-memory train_callback.df\")\n",
    "        return train_callback.df.copy()\n",
    "    raise FileNotFoundError(\"No training dataset found. Ensure train_steps.csv exists or run training first.\")\n",
    "\n",
    "df_steps = _load_policy_dataset()\n",
    "\n",
    "feat_cols = sorted([c for c in df_steps.columns if c.startswith(\"x\")],\n",
    "                   key=lambda c: int(c[1:]) if c[1:].isdigit() else 1e9)\n",
    "\n",
    "# Map to CityLearn observation names for readability (single-building)\n",
    "feature_names = feat_cols\n",
    "try:\n",
    "    obs_names = eval_env.unwrapped.observation_names[0]  # Building_1\n",
    "    if len(obs_names) == len(feat_cols):\n",
    "        feature_names = list(obs_names)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "X = df_steps[feat_cols].to_numpy() # flattened observations\n",
    "y = df_steps['action_id'].astype(int).to_numpy() # actions the DQN took\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)\n",
    "\n",
    "\"\"\"\n",
    "# 3) Train a compact tree (tune depth/leaves for your preference)\n",
    "# Greedily picks the feature and threshold that best split \n",
    "# the training data to reduce class impurity (default: gini)\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", # \n",
    "    max_depth=4,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=0,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\"\"\"\n",
    "# Hyperparameter optimization with GridSearchCV\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, None],\n",
    "    \"min_samples_leaf\": [1, 5, 10, 25, 50],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"ccp_alpha\": [0.0, 0.0005, 0.001, 0.005],\n",
    "    \"splitter\": [\"best\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) # keeps class proportions similar in each fold\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best balanced_accuracy:\", grid.best_score_)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "# Evaluate fidelity to the DQN policy\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred) # fraction of correctly classified samples\n",
    "print(f\"Surrogate Tree Accuracy: {acc:.3f}\")\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=ACTION_LABELS))\n",
    "\n",
    "# Global explanations\n",
    "print(\"\\nTop feature importances:\")\n",
    "imp_idx = np.argsort(clf.feature_importances_)[::-1]\n",
    "for i in imp_idx[:10]:\n",
    "    if clf.feature_importances_[i] <= 0: break\n",
    "    print(f\"- {feature_names[i]}: {clf.feature_importances_[i]:.4f}\")\n",
    "\n",
    "#print(\"\\nTree rules (text form):\")\n",
    "#print(export_text(clf, feature_names=feature_names))\n",
    "\n",
    "\n",
    "# Local explanation for a single timestep\n",
    "def explain_sample(idx_in_df: int):\n",
    "    \"\"\"Print the decision path for a given row index from df_steps.\"\"\"\n",
    "    x = df_steps.iloc[idx_in_df][feat_cols].to_numpy().reshape(1, -1)\n",
    "    true_a = int(df_steps.iloc[idx_in_df]['action'])\n",
    "    pred_a = int(clf.predict(x)[0])\n",
    "    proba  = clf.predict_proba(x)[0]\n",
    "    tree = clf.tree_\n",
    "    node = 0\n",
    "    path = []\n",
    "    while tree.feature[node] != -2:  # -2 => leaf\n",
    "        f_idx = tree.feature[node]\n",
    "        thr = tree.threshold[node]\n",
    "        val = float(x[0, f_idx])\n",
    "        go_left = val <= thr\n",
    "        path.append((feature_names[f_idx], val, thr, \"left\" if go_left else \"right\"))\n",
    "        node = tree.children_left[node] if go_left else tree.children_right[node]\n",
    "    print(f\"True action: {true_a} ({ACTION_LABELS[true_a]}), \"\n",
    "          f\"Pred: {pred_a} ({ACTION_LABELS[pred_a]}), \"\n",
    "          f\"Proba: {dict(zip(ACTION_LABELS, np.round(proba,3)))}\")\n",
    "    print(\"Decision path:\")\n",
    "    for name, val, thr, side in path:\n",
    "        print(f\" - {name}: {val:.4f} <= {thr:.4f} -> {side}\")\n",
    "    return pred_a\n",
    "\n",
    "# Example: Random sample from the dataset\n",
    "_ = explain_sample(idx_in_df=np.random.randint(0, len(df_steps)))\n",
    "\n",
    "# Visualization with Graphviz (SVG)\n",
    "try:\n",
    "    from sklearn.tree import export_graphviz\n",
    "    import graphviz\n",
    "    from IPython.display import SVG, display\n",
    "\n",
    "    dot = export_graphviz(\n",
    "        clf,\n",
    "        out_file=None,\n",
    "        feature_names=feature_names,\n",
    "        class_names=ACTION_LABELS,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True,\n",
    "    )\n",
    "    src = graphviz.Source(dot)\n",
    "    display(SVG(src.pipe(format='svg')))  # crisp, scalable, no overlaps\n",
    "except Exception as e:\n",
    "    print(\"Graphviz unavailable; falling back to matplotlib (may overlap). Error:\", e)\n",
    "    plt.figure(figsize=(32, 16), dpi=250)\n",
    "    plot_tree(\n",
    "        clf,\n",
    "        feature_names=feature_names,\n",
    "        class_names=ACTION_LABELS,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        max_depth=4,\n",
    "        fontsize=14\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (citylearn_env)",
   "language": "python",
   "name": "citylearn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
