{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b23e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a0fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 09:06:58.750046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-05 09:06:58.763389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754377618.777472 2388095 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754377618.781529 2388095 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754377618.792963 2388095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754377618.792979 2388095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754377618.792980 2388095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754377618.792982 2388095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-05 09:06:58.797262: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# System operations\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "# Date and time\n",
    "from datetime import datetime\n",
    "\n",
    "# Type hinting\n",
    "from typing import Any, List, Mapping, Tuple, Union\n",
    "\n",
    "# Data manipulation\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import simplejson as json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# User interaction\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Button, FloatSlider, HBox, HTML, IntProgress, Text, VBox\n",
    "\n",
    "# CityLearn\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.data import DataSet\n",
    "from citylearn.reward_function import RewardFunction, SolarPenaltyReward, ComfortReward\n",
    "from citylearn.wrappers import NormalizedObservationWrapper, StableBaselines3Wrapper, TabularQLearningWrapper\n",
    "from citylearn.agents.rbc import BasicRBC\n",
    "from citylearn.agents.q_learning import TabularQLearning\n",
    "\n",
    "# Baseline RL algorithms\n",
    "from stable_baselines3 import DQN, SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecNormalize, VecMonitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa1c0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Go here /home/iai/cj9272/.cache/citylearn/v2.4.1/datasets/citylearn_challenge_2023_phase_3_1/schema.json \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iai/cj9272/.cache/citylearn/v2.4.1/datasets/citylearn_challenge_2023_phase_3_1\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'citylearn_challenge_2023_phase_3_1'\n",
    "schema = DataSet().get_schema(DATASET_NAME)\n",
    "print(schema['root_directory'])\n",
    "\n",
    "# Building\n",
    "#root_directory = schema['root_directory']\n",
    "root_directory = 'Bachelorthesis_DQN_Agent/data/datasets/citylearn_challenge_2023_phase_3_1'\n",
    "building_name = 'Building_1'\n",
    "# Weather data\n",
    "filename = schema['buildings'][building_name]['weather']\n",
    "filepath = os.path.join(root_directory, filename)\n",
    "weather_data = pd.read_csv(filepath)\n",
    "# Pricing data (simple)\n",
    "filename = schema['buildings'][building_name]['pricing']\n",
    "filepath = os.path.join(root_directory, filename)\n",
    "pricing_data = pd.read_csv(filepath)\n",
    "# building data\n",
    "filename = schema['buildings'][building_name]['energy_simulation']\n",
    "filepath = os.path.join(root_directory, filename)\n",
    "building_data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8152abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_active_observations( # from tutorial\n",
    "    schema: dict, active_observations: List[str]\n",
    ") -> dict:\n",
    "    \"\"\"Set the observations that will be part of the environment's\n",
    "    observation space that is provided to the control agent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    schema: dict\n",
    "        CityLearn dataset mapping used to construct environment.\n",
    "    active_observations: List[str]\n",
    "        Names of observations to set active to be passed to control agent.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    schema: dict\n",
    "        CityLearn dataset mapping with active observations set.\n",
    "    \"\"\"\n",
    "\n",
    "    active_count = 0\n",
    "\n",
    "    for o in schema['observations']:\n",
    "        if o in active_observations:\n",
    "            schema['observations'][o]['active'] = True\n",
    "            active_count += 1\n",
    "        else:\n",
    "            schema['observations'][o]['active'] = False\n",
    "\n",
    "    valid_observations = list(schema['observations'].keys())\n",
    "    assert active_count == len(active_observations),\\\n",
    "        'the provided observations are not all valid observations.'\\\n",
    "          f' Valid observations in CityLearn are: {valid_observations}'\n",
    "\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d9bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_building_guide(env):\n",
    "    \"\"\"Plots building load and generation profiles for a single building.\"\"\"\n",
    "\n",
    "    b = env.buildings[0]\n",
    "    y1 = b.energy_simulation.non_shiftable_load\n",
    "    y2 = b.pv.get_generation(b.energy_simulation.solar_generation)\n",
    "    x = range(len(y1))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    ax.plot(x, y1, label='Non Shiftable Load')\n",
    "    ax.plot(x, y2, label='Solar Generation')\n",
    "    ax.set_title(b.name)\n",
    "    ax.set_xlabel('Time step')\n",
    "    ax.set_ylabel('kWh')\n",
    "    ax.legend(loc='upper left', framealpha=0.0)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c5313",
   "metadata": {},
   "source": [
    "# Optimize a Soft-Actor Critic Reinforcement Learning Controller\n",
    "---\n",
    "\n",
    "To control an environment like CityLearn that has continuous states and actions, tabular Q-learning is not practical, as it suffers from the _curse of dimensionality_. Actor-critic reinforcement learning (RL) methods use artificial neural networks to generalize across the state-action space. The actor network maps the current states to the actions that it estimates to be optimal. Then, the critic network evaluates those actions by mapping them, together with the states under which they were taken, to the Q-values.\n",
    "\n",
    "<figure class=\"image\">\n",
    "  <img src=\"https://github.com/intelligent-environments-lab/CityLearn/blob/master/assets/images/sac_schematic.png?raw=true\"  width=\"350\" alt=\"SAC networks overview.\">\n",
    "  <figcaption>Figure: SAC networks overview (adopted from <a href=\"https://doi.org/10.1145/3408308.3427604\">Vazquez-Canteli et al., 2020</a>).</figcaption>\n",
    "</figure>\n",
    "\n",
    "Soft actor-critic (SAC) is a model-free off-policy RL algorithm. As an off-policy method, SAC can reuse experience and learn from fewer samples. SAC is based on three key elements: an actor-critic architecture, off-policy updates, and entropy maximization for efficient exploration and stable training. SAC learns three different functions: the actor (policy), the critic (soft Q-function), and the value function.\n",
    "\n",
    "This tutorial does not dive into the theory and algorithm of SAC but for interested participants please, refer to [Soft Actor-Critic Algorithms and Applications](https://doi.org/10.48550/arXiv.1812.05905).\n",
    "\n",
    "We will now initialize a new environment and plug it to an SAC agent to help us solve our control problem. Luckily, we do not have to write our own implementation of the SAC algorithm. Instead, we can make use of Python libraries that have standardized the implementation of a number of RL algorithms. One of such libraries that we will use is [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/index.html). At the time of writing, there are [13 different RL algorithms](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html#rl-algorithms) implemented between Stable Baselines3 and Stable-Baselines3 - Contrib (contrib package for Stable-Baselines3 - experimental reinforcement learning code), including SAC.\n",
    "\n",
    "<!-- The new environment is initialized below: -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d26fcc",
   "metadata": {},
   "source": [
    "Before our environment is ready for use in Stable Baselines3, we need to take a couple of preprocessing steps in the form of wrappers. Firstly, we will wrap the environment using the `NormalizedObservationWrapper` (see [docs](https://www.citylearn.net/api/citylearn.wrappers.html#citylearn.wrappers.NormalizedObservationWrapper)) that ensure all observations that are served to the agent are [min-max normalized](https://www.codecademy.com/article/normalization) between [0, 1] and cyclical observations e.g. hour, are encoded using the [sine and cosine transformation](https://www.avanwyk.com/encoding-cyclical-features-for-deep-learning/).\n",
    "\n",
    "Next, we wrap with the `StableBaselines3Wrapper` (see [docs](https://www.citylearn.net/api/citylearn.wrappers.html#citylearn.wrappers.StableBaselines3Wrapper)) that ensures observations, actions and rewards are served in manner that is compatible with Stable Baselines3 interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(verbose=0)\n",
    "        self.env = env\n",
    "        self.citylearn_env = env.unwrapped\n",
    "        self.reward_history = [0]\n",
    "        self.episode_count = 0\n",
    "        self.last_episode_printed = -1  # Track which episode was last printed\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.citylearn_env.time_step == 0:\n",
    "            self.reward_history.append(0)\n",
    "            self.episode_count += 1\n",
    "            \n",
    "            # Only print if we haven't printed this episode yet\n",
    "            if self.episode_count != self.last_episode_printed:\n",
    "                if len(self.reward_history) > 1:  # Make sure we have a previous reward to show\n",
    "                    prev_reward = self.reward_history[-2]\n",
    "                    print(f\"Episode {self.episode_count}/5 completed. Reward: {prev_reward:.2f}\")\n",
    "                    self.last_episode_printed = self.episode_count\n",
    "        else:\n",
    "            # Accumulate rewards during the episode\n",
    "            self.reward_history[-1] += sum(self.citylearn_env.rewards[-1])\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b7dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iai/cj9272/.cache/citylearn/v2.4.1/datasets/citylearn_challenge_2023_phase_3_1\n",
      "Dataset '/home/iai/cj9272/.cache/citylearn/v2.4.1/datasets/citylearn_challenge_2023_phase_3_1' copied to '/home/iai/cj9272/.cache/citylearn/v2.4.1/datasets/citylearn_challenge_2023_phase_3_1/../../../../results/2025-08-05_09-37-20'\n",
      "\n",
      "Active observations: ['hour']\n"
     ]
    }
   ],
   "source": [
    "ACTIVE_OBSERVATIONS = ['hour']\n",
    "\n",
    "schema = set_active_observations(schema, ACTIVE_OBSERVATIONS)\n",
    "\n",
    "sac_env = CityLearnEnv(\n",
    "    schema, \n",
    "    central_agent=True, \n",
    "    buildings=[0],\n",
    ")\n",
    "sac_env.reward_function = SolarPenaltyReward(sac_env.get_metadata())\n",
    "sac_env = NormalizedObservationWrapper(sac_env)\n",
    "sac_env = StableBaselines3Wrapper(sac_env)\n",
    "\n",
    "\n",
    "sac_model = SAC(policy='MlpPolicy', env=sac_env, seed=42)\n",
    "print(f\"\\nActive observations: {[k for k, v in schema['observations'].items() if v['active']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17774598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of Tabular Q-Learning episodes used: 0.25\n",
      "Number of episodes to train: 5\n",
      "Episode 1/10 completed. Reward: 0.00\n",
      "Episode 1/10 completed. Reward: 0.00\n",
      "Episode 2/10 completed. Reward: 0.00\n",
      "Episode 2/10 completed. Reward: 0.00\n",
      "Episode 3/10 completed. Reward: 0.00\n",
      "Episode 3/10 completed. Reward: 0.00\n",
      "Episode 4/10 completed. Reward: 0.00\n",
      "Episode 4/10 completed. Reward: 0.00\n",
      "Episode 5/10 completed. Reward: 0.00\n",
      "Episode 5/10 completed. Reward: 0.00\n"
     ]
    }
   ],
   "source": [
    "# ----------------- CALCULATE NUMBER OF TRAINING EPISODES -----------------\n",
    "fraction = 0.25\n",
    "#sac_episodes = int(tql_episodes*fraction)\n",
    "sac_episodes = 5\n",
    "print('Fraction of Tabular Q-Learning episodes used:', fraction)\n",
    "print('Number of episodes to train:', sac_episodes)\n",
    "sac_episode_timesteps = schema['simulation_end_time_step'] - schema['simulation_start_time_step'] + 1\n",
    "sac_total_timesteps = sac_episodes * sac_episode_timesteps\n",
    "\n",
    "# ------------------------------- TRAIN MODEL -----------------------------\n",
    "sac_callback = CustomCallback(env=sac_env)\n",
    "sac_model = sac_model.learn(\n",
    "    total_timesteps=sac_total_timesteps,\n",
    "    callback=sac_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f278b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode: 5/10\n",
      "Episodes completed: 5\n",
      "Recent episode rewards: [np.float32(0.0), np.float32(0.0), np.float32(0.0)]\n",
      "Average recent reward: 0.00\n"
     ]
    }
   ],
   "source": [
    "# PROGRESS CHECK (run this in a separate cell if training is still running)\n",
    "# This won't interrupt training but shows current status\n",
    "\n",
    "# Check if callback exists and has data\n",
    "if 'sac_callback' in locals() and hasattr(sac_callback, 'episode_count'):\n",
    "    print(f\"Current episode: {sac_callback.episode_count}/10\")\n",
    "    print(f\"Episodes completed: {len(sac_callback.reward_history)-1}\")\n",
    "    if len(sac_callback.reward_history) > 1:\n",
    "        recent_rewards = sac_callback.reward_history[-3:]  # Show last 3 episodes\n",
    "        print(f\"Recent episode rewards: {recent_rewards}\")\n",
    "        print(f\"Average recent reward: {np.mean(recent_rewards):.2f}\")\n",
    "else:\n",
    "    print(\"Training callback not available or training not started yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08db4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= AGENT COMPARISON TOOLS (FIXED) =========================\n",
    "\n",
    "def evaluate_agent(agent, env, episodes=5, agent_type=\"Unknown\"):\n",
    "    \"\"\"Evaluate an agent and collect metrics.\"\"\"\n",
    "    \n",
    "    # Reset environment for evaluation\n",
    "    env_copy = env.unwrapped if hasattr(env, 'unwrapped') else env\n",
    "    \n",
    "    episode_rewards = []\n",
    "    episode_costs = []\n",
    "    episode_consumption = []\n",
    "    episode_solar_used = []\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        # Fix: Handle the SB3 environment API correctly\n",
    "        reset_result = env.reset()\n",
    "        if isinstance(reset_result, tuple):\n",
    "            obs, info = reset_result  # SB3 API returns (obs, info)\n",
    "        else:\n",
    "            obs = reset_result  # Older API returns just obs\n",
    "            \n",
    "        episode_reward = 0\n",
    "        episode_cost = 0\n",
    "        episode_consumption_total = 0\n",
    "        episode_solar_total = 0\n",
    "        \n",
    "        done = False\n",
    "        step = 0\n",
    "        \n",
    "        while not done and step < 8760:  # Limit steps to prevent infinite loops\n",
    "            if agent_type == \"RBC\":\n",
    "                # For RBC agent - it expects different observation format\n",
    "                if hasattr(agent, 'env') and hasattr(agent.env, 'observations'):\n",
    "                    rbc_obs = agent.env.observations\n",
    "                    action = agent.predict(rbc_obs)\n",
    "                else:\n",
    "                    if isinstance(obs, np.ndarray) and obs.ndim == 1:\n",
    "                        action = agent.predict([obs])  # Wrap in list for RBC\n",
    "                    else:\n",
    "                        action = agent.predict(obs)\n",
    "            else:\n",
    "                # For SAC agent (Stable Baselines3)\n",
    "                action, _ = agent.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Fix: Handle step result correctly too\n",
    "            step_result = env.step(action)\n",
    "            if len(step_result) == 4:\n",
    "                obs, reward, done, info = step_result\n",
    "            else:\n",
    "                obs, reward, terminated, truncated, info = step_result\n",
    "                done = terminated or truncated\n",
    "            \n",
    "            # Fix: Handle different reward types\n",
    "            if isinstance(reward, (list, tuple, np.ndarray)):\n",
    "                episode_reward += sum(reward)\n",
    "            else:\n",
    "                episode_reward += float(reward)  # Handle numpy.float32 and other numeric types\n",
    "            \n",
    "            # ========================= FIXED COST AND CONSUMPTION METRICS =========================\n",
    "            if hasattr(env_copy, 'buildings') and len(env_copy.buildings) > 0:\n",
    "                building = env_copy.buildings[0]\n",
    "                \n",
    "                # Get current consumption (VERIFIED: this works)\n",
    "                if hasattr(building, 'net_electricity_consumption') and len(building.net_electricity_consumption) > 0:\n",
    "                    current_consumption = building.net_electricity_consumption[-1]\n",
    "                    episode_consumption_total += abs(current_consumption)\n",
    "                    \n",
    "                    # Calculate cost using pricing data (VERIFIED: this works)\n",
    "                    if hasattr(building, 'pricing') and hasattr(building.pricing, 'electricity_pricing'):\n",
    "                        if len(building.pricing.electricity_pricing) > 0:\n",
    "                            current_price = building.pricing.electricity_pricing[-1]\n",
    "                            episode_cost += abs(current_consumption * current_price)  # Use abs to ensure positive cost\n",
    "                \n",
    "                # FIXED: Solar generation using correct method\n",
    "                solar_gen = 0\n",
    "                if hasattr(building, 'energy_simulation') and hasattr(building.energy_simulation, 'solar_generation'):\n",
    "                    solar_generation_data = building.energy_simulation.solar_generation\n",
    "                    if hasattr(solar_generation_data, '__len__') and len(solar_generation_data) > 0:\n",
    "                        # Get current solar generation from energy simulation data\n",
    "                        current_time_step = building.time_step if hasattr(building, 'time_step') else step\n",
    "                        if current_time_step < len(solar_generation_data):\n",
    "                            solar_gen = solar_generation_data[current_time_step]\n",
    "                        else:\n",
    "                            solar_gen = solar_generation_data[-1]  # Use last available value\n",
    "                \n",
    "                episode_solar_total += solar_gen\n",
    "            \n",
    "            step += 1\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_costs.append(episode_cost)\n",
    "        episode_consumption.append(episode_consumption_total)\n",
    "        episode_solar_used.append(episode_solar_total)\n",
    "        \n",
    "        print(f\"{agent_type} Episode {episode+1}/{episodes} - Reward: {episode_reward:.2f}, Cost: ${episode_cost:.2f}, Consumption: {episode_consumption_total:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'agent_type': agent_type,\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_costs': episode_costs,\n",
    "        'episode_consumption': episode_consumption,\n",
    "        'episode_solar_used': episode_solar_used,\n",
    "        'avg_reward': np.mean(episode_rewards),\n",
    "        'avg_cost': np.mean(episode_costs),\n",
    "        'avg_consumption': np.mean(episode_consumption),\n",
    "        'avg_solar_used': np.mean(episode_solar_used)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5449adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agent_comparison(sac_results, rbc_results):\n",
    "    \"\"\"Plot comprehensive comparison between SAC and RBC agents.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('SAC vs RBC Agent Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Episode Rewards Comparison\n",
    "    axes[0, 0].plot(sac_results['episode_rewards'], 'b-o', label='SAC', linewidth=2, markersize=6)\n",
    "    axes[0, 0].plot(rbc_results['episode_rewards'], 'r-s', label='RBC', linewidth=2, markersize=6)\n",
    "    axes[0, 0].set_title('Episode Rewards Comparison')\n",
    "    axes[0, 0].set_xlabel('Episode')\n",
    "    axes[0, 0].set_ylabel('Total Reward')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Episode Costs Comparison\n",
    "    axes[0, 1].plot(sac_results['episode_costs'], 'b-o', label='SAC', linewidth=2, markersize=6)\n",
    "    axes[0, 1].plot(rbc_results['episode_costs'], 'r-s', label='RBC', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_title('Episode Costs Comparison')\n",
    "    axes[0, 1].set_xlabel('Episode')\n",
    "    axes[0, 1].set_ylabel('Total Cost ($)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Average Performance Bar Chart\n",
    "    metrics = ['Avg Reward', 'Avg Cost', 'Avg Consumption', 'Avg Solar Used']\n",
    "    sac_values = [sac_results['avg_reward'], sac_results['avg_cost'], \n",
    "                  sac_results['avg_consumption'], sac_results['avg_solar_used']]\n",
    "    rbc_values = [rbc_results['avg_reward'], rbc_results['avg_cost'], \n",
    "                  rbc_results['avg_consumption'], rbc_results['avg_solar_used']]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 0].bar(x - width/2, sac_values, width, label='SAC', color='blue', alpha=0.7)\n",
    "    axes[1, 0].bar(x + width/2, rbc_values, width, label='RBC', color='red', alpha=0.7)\n",
    "    axes[1, 0].set_title('Average Performance Metrics')\n",
    "    axes[1, 0].set_ylabel('Value')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(metrics, rotation=45, ha='right')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Performance Summary Table\n",
    "    axes[1, 1].axis('tight')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'SAC', 'RBC', 'SAC vs RBC'],\n",
    "        ['Avg Reward', f'{sac_results[\"avg_reward\"]:.2f}', f'{rbc_results[\"avg_reward\"]:.2f}', \n",
    "         f'{((sac_results[\"avg_reward\"] - rbc_results[\"avg_reward\"]) / abs(rbc_results[\"avg_reward\"]) * 100):+.1f}%'],\n",
    "        ['Avg Cost ($)', f'{sac_results[\"avg_cost\"]:.2f}', f'{rbc_results[\"avg_cost\"]:.2f}', \n",
    "         f'{((sac_results[\"avg_cost\"] - rbc_results[\"avg_cost\"]) / abs(rbc_results[\"avg_cost\"]) * 100):+.1f}%'],\n",
    "        ['Avg Consumption', f'{sac_results[\"avg_consumption\"]:.2f}', f'{rbc_results[\"avg_consumption\"]:.2f}', \n",
    "         f'{((sac_results[\"avg_consumption\"] - rbc_results[\"avg_consumption\"]) / abs(rbc_results[\"avg_consumption\"]) * 100):+.1f}%'],\n",
    "        ['Avg Solar Used', f'{sac_results[\"avg_solar_used\"]:.2f}', f'{rbc_results[\"avg_solar_used\"]:.2f}', \n",
    "         f'{((sac_results[\"avg_solar_used\"] - rbc_results[\"avg_solar_used\"]) / abs(rbc_results[\"avg_solar_used\"]) * 100):+.1f}%']\n",
    "    ]\n",
    "    \n",
    "    table = axes[1, 1].table(cellText=table_data[1:], colLabels=table_data[0], \n",
    "                            cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "    axes[1, 1].set_title('Performance Summary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36df6787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DEBUGGING BUILDING OBJECT ATTRIBUTES\n",
      "==================================================\n",
      "‚úì SAC model found - inspecting building...\n",
      "\n",
      "üè¢ Building Type: LSTMDynamicsBuilding\n",
      "üè¢ Building Name: Building_1\n",
      "\n",
      "üîç Key Attributes Check:\n",
      "‚úÖ net_electricity_consumption: <class 'numpy.ndarray'> (length: 1)\n",
      "   Current value: 0.4156108498573303\n",
      "‚úÖ pricing: Pricing\n",
      "   ‚úÖ electricity_pricing: <class 'numpy.ndarray'> (length: 2208)\n",
      "      Current price: 0.030249999836087227\n",
      "‚úÖ pv: PV\n",
      "   ‚ùå electricity_generation: NOT FOUND\n",
      "   Available PV attributes: ['DEFAULT_RANDOM_SEED_RANGE', 'DEFAULT_SECONDS_PER_TIME_STEP', 'autosize_config', 'available_nominal_power', 'efficiency', 'electricity_consumption', 'episode_tracker', 'nominal_power', 'numpy_random_state', 'random_seed']\n",
      "‚úÖ energy_simulation: EnergySimulation\n",
      "   ‚úÖ solar_generation: <class 'numpy.ndarray'> (length: 2208)\n",
      "      Current solar: 0.0\n",
      "\n",
      "üìã All Building Attributes (non-callable):\n",
      "\n",
      "DEFAULT_RANDOM_SEED_RANGEDEFAULT_SECONDS_PER_TIME_STEPaction_metadata     action_space        active_actions      \n",
      "active_observations algorithm_action_based_time_step_hours_ratiocarbon_intensity    chargers_electricity_consumptioncomfort_band        \n",
      "cooling_demand      cooling_demand_without_partial_loadcooling_device      cooling_device_cop  cooling_electricity_consumption\n",
      "cooling_storage     cooling_storage_electricity_consumptiondemand_observation_limit_factordhw_demand          dhw_device          \n",
      "dhw_device_cop      dhw_electricity_consumptiondhw_storage         dhw_storage_electricity_consumptiondownward_electrical_flexibility\n",
      "electric_vehicle_chargerselectrical_storage  electrical_storage_electricity_consumptionenergy_from_cooling_deviceenergy_from_cooling_device_to_cooling_storage\n",
      "energy_from_cooling_storageenergy_from_dhw_deviceenergy_from_dhw_device_to_dhw_storageenergy_from_dhw_storageenergy_from_electrical_storage\n",
      "energy_from_heating_deviceenergy_from_heating_device_to_heating_storageenergy_from_heating_storageenergy_simulation   energy_to_electrical_storage\n",
      "energy_to_non_shiftable_loadepisode_tracker     heating_demand      heating_demand_without_partial_loadheating_device      \n",
      "heating_device_cop  heating_electricity_consumptionheating_storage     heating_storage_electricity_consumptionignore_dynamics     \n",
      "indoor_dry_bulb_temperatureindoor_dry_bulb_temperature_cooling_set_pointindoor_dry_bulb_temperature_heating_set_pointindoor_dry_bulb_temperature_without_partial_loadmaximum_temperature_delta\n",
      "name                net_electricity_consumptionnet_electricity_consumption_costnet_electricity_consumption_cost_without_storagenet_electricity_consumption_cost_without_storage_and_partial_load\n",
      "net_electricity_consumption_cost_without_storage_and_partial_load_and_pvnet_electricity_consumption_cost_without_storage_and_pvnet_electricity_consumption_emissionnet_electricity_consumption_emission_without_storagenet_electricity_consumption_emission_without_storage_and_partial_load\n",
      "net_electricity_consumption_emission_without_storage_and_partial_load_and_pvnet_electricity_consumption_emission_without_storage_and_pvnet_electricity_consumption_without_storagenet_electricity_consumption_without_storage_and_partial_loadnet_electricity_consumption_without_storage_and_partial_load_and_pv\n",
      "net_electricity_consumption_without_storage_and_pvnon_periodic_normalized_observation_space_limitsnon_shiftable_load  non_shiftable_load_devicenon_shiftable_load_electricity_consumption\n",
      "numpy_random_state  observation_metadataobservation_space   observation_space_limit_deltaoccupant_count      \n",
      "periodic_normalized_observation_space_limitspower_outage        power_outage_signal pricing             pv                  \n",
      "random_seed         seconds_per_time_stepsimulate_dynamics   simulate_power_outagesolar_generation    \n",
      "stochastic_power_outagestochastic_power_outage_modeltime_step           time_step_ratio     uid                 \n",
      "washing_machines    washing_machines_electricity_consumptionweather             \n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================= DEBUG BUILDING ATTRIBUTES =========================\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"DEBUGGING BUILDING OBJECT ATTRIBUTES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if SAC model is available\n",
    "if 'sac_model' in locals() and 'sac_env' in locals():\n",
    "    print(\"‚úì SAC model found - inspecting building...\")\n",
    "    \n",
    "    # Reset environment to get building object\n",
    "    env_copy = sac_env.unwrapped if hasattr(sac_env, 'unwrapped') else sac_env\n",
    "    reset_result = sac_env.reset()\n",
    "    \n",
    "    if hasattr(env_copy, 'buildings') and len(env_copy.buildings) > 0:\n",
    "        building = env_copy.buildings[0]\n",
    "        print(f\"\\nüè¢ Building Type: {type(building).__name__}\")\n",
    "        print(f\"üè¢ Building Name: {getattr(building, 'name', 'Unknown')}\")\n",
    "        \n",
    "        # Check key attributes for cost/consumption calculation\n",
    "        print(f\"\\nüîç Key Attributes Check:\")\n",
    "        \n",
    "        # 1. Net electricity consumption\n",
    "        if hasattr(building, 'net_electricity_consumption'):\n",
    "            net_elec = getattr(building, 'net_electricity_consumption')\n",
    "            print(f\"‚úÖ net_electricity_consumption: {type(net_elec)} (length: {len(net_elec) if hasattr(net_elec, '__len__') else 'N/A'})\")\n",
    "            if hasattr(net_elec, '__len__') and len(net_elec) > 0:\n",
    "                print(f\"   Current value: {net_elec[-1]}\")\n",
    "        else:\n",
    "            print(f\"‚ùå net_electricity_consumption: NOT FOUND\")\n",
    "            \n",
    "        # 2. Pricing information\n",
    "        if hasattr(building, 'pricing'):\n",
    "            pricing = getattr(building, 'pricing')\n",
    "            print(f\"‚úÖ pricing: {type(pricing).__name__}\")\n",
    "            \n",
    "            # Check electricity pricing\n",
    "            if hasattr(pricing, 'electricity_pricing'):\n",
    "                elec_pricing = getattr(pricing, 'electricity_pricing')\n",
    "                print(f\"   ‚úÖ electricity_pricing: {type(elec_pricing)} (length: {len(elec_pricing) if hasattr(elec_pricing, '__len__') else 'N/A'})\")\n",
    "                if hasattr(elec_pricing, '__len__') and len(elec_pricing) > 0:\n",
    "                    print(f\"      Current price: {elec_pricing[-1]}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå electricity_pricing: NOT FOUND\")\n",
    "                # Show available pricing attributes\n",
    "                pricing_attrs = [attr for attr in dir(pricing) if not attr.startswith('_') and not callable(getattr(pricing, attr))]\n",
    "                print(f\"   Available pricing attributes: {pricing_attrs[:10]}\")  # Show first 10\n",
    "        else:\n",
    "            print(f\"‚ùå pricing: NOT FOUND\")\n",
    "            \n",
    "        # 3. Solar/PV information\n",
    "        if hasattr(building, 'pv'):\n",
    "            pv = getattr(building, 'pv')\n",
    "            print(f\"‚úÖ pv: {type(pv).__name__ if pv is not None else 'None'}\")\n",
    "            \n",
    "            if pv is not None:\n",
    "                # Check electricity generation\n",
    "                if hasattr(pv, 'electricity_generation'):\n",
    "                    elec_gen = getattr(pv, 'electricity_generation')\n",
    "                    print(f\"   ‚úÖ electricity_generation: {type(elec_gen)} (length: {len(elec_gen) if hasattr(elec_gen, '__len__') else 'N/A'})\")\n",
    "                    if hasattr(elec_gen, '__len__') and len(elec_gen) > 0:\n",
    "                        print(f\"      Current generation: {elec_gen[-1]}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå electricity_generation: NOT FOUND\")\n",
    "                    pv_attrs = [attr for attr in dir(pv) if not attr.startswith('_') and not callable(getattr(pv, attr))]\n",
    "                    print(f\"   Available PV attributes: {pv_attrs[:10]}\")  # Show first 10\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  PV object is None\")\n",
    "        else:\n",
    "            print(f\"‚ùå pv: NOT FOUND\")\n",
    "            \n",
    "        # 4. Energy simulation data\n",
    "        if hasattr(building, 'energy_simulation'):\n",
    "            energy_sim = getattr(building, 'energy_simulation')\n",
    "            print(f\"‚úÖ energy_simulation: {type(energy_sim).__name__}\")\n",
    "            \n",
    "            if hasattr(energy_sim, 'solar_generation'):\n",
    "                solar_gen = getattr(energy_sim, 'solar_generation')\n",
    "                print(f\"   ‚úÖ solar_generation: {type(solar_gen)} (length: {len(solar_gen) if hasattr(solar_gen, '__len__') else 'N/A'})\")\n",
    "                if hasattr(solar_gen, '__len__') and len(solar_gen) > 0:\n",
    "                    print(f\"      Current solar: {solar_gen[-1] if hasattr(solar_gen, '__getitem__') else 'Cannot access'}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå solar_generation: NOT FOUND\")\n",
    "                energy_attrs = [attr for attr in dir(energy_sim) if not attr.startswith('_') and not callable(getattr(energy_sim, attr))]\n",
    "                print(f\"   Available energy_simulation attributes: {energy_attrs[:10]}\")  # Show first 10\n",
    "        else:\n",
    "            print(f\"‚ùå energy_simulation: NOT FOUND\")\n",
    "            \n",
    "        # 5. Show all non-callable attributes\n",
    "        print(f\"\\nüìã All Building Attributes (non-callable):\")\n",
    "        all_attrs = [attr for attr in dir(building) if not attr.startswith('_') and not callable(getattr(building, attr))]\n",
    "        for i, attr in enumerate(all_attrs):\n",
    "            if i % 5 == 0:\n",
    "                print()\n",
    "            print(f\"{attr:<20}\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No buildings found in environment\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå SAC model not found. Please run the training cell first.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edaba1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Essential Building Attributes:\n",
      "‚úÖ net_electricity_consumption: ndarray\n",
      "   ‚îî‚îÄ length: 1\n",
      "‚úÖ pricing: Pricing\n",
      "   ‚îî‚îÄ electricity_pricing: length=2208\n",
      "‚úÖ pv: PV\n",
      "‚úÖ energy_simulation: EnergySimulation\n",
      "   ‚îî‚îÄ solar_generation: length=2208\n",
      "   ‚îî‚îÄ non_shiftable_load: length=2208\n",
      "‚úÖ electrical_storage: Battery\n",
      "‚úÖ cooling_device: HeatPump\n",
      "‚úÖ heating_device: HeatPump\n",
      "\n",
      "üí° Try accessing net_electricity_consumption...\n",
      "   Current consumption: 0.4156108498573303\n"
     ]
    }
   ],
   "source": [
    "# ========================= MINIMAL BUILDING DEBUG =========================\n",
    "\n",
    "if 'sac_env' in locals():\n",
    "    env_copy = sac_env.unwrapped if hasattr(sac_env, 'unwrapped') else sac_env\n",
    "    sac_env.reset()\n",
    "    \n",
    "    if hasattr(env_copy, 'buildings') and len(env_copy.buildings) > 0:\n",
    "        building = env_copy.buildings[0]\n",
    "        print(\"üîç Essential Building Attributes:\")\n",
    "        \n",
    "        # Check what we can actually access for metrics\n",
    "        attrs_to_check = [\n",
    "            'net_electricity_consumption',\n",
    "            'pricing',\n",
    "            'pv', \n",
    "            'energy_simulation',\n",
    "            'electrical_storage',\n",
    "            'cooling_device',\n",
    "            'heating_device'\n",
    "        ]\n",
    "        \n",
    "        for attr in attrs_to_check:\n",
    "            if hasattr(building, attr):\n",
    "                obj = getattr(building, attr)\n",
    "                if obj is not None:\n",
    "                    print(f\"‚úÖ {attr}: {type(obj).__name__}\")\n",
    "                    \n",
    "                    # Special handling for pricing\n",
    "                    if attr == 'pricing' and hasattr(obj, 'electricity_pricing'):\n",
    "                        elec_pricing = getattr(obj, 'electricity_pricing')\n",
    "                        print(f\"   ‚îî‚îÄ electricity_pricing: length={len(elec_pricing) if hasattr(elec_pricing, '__len__') else 'N/A'}\")\n",
    "                        \n",
    "                    # Special handling for pv\n",
    "                    elif attr == 'pv' and hasattr(obj, 'electricity_generation'):\n",
    "                        elec_gen = getattr(obj, 'electricity_generation')\n",
    "                        print(f\"   ‚îî‚îÄ electricity_generation: length={len(elec_gen) if hasattr(elec_gen, '__len__') else 'N/A'}\")\n",
    "                        \n",
    "                    # Special handling for energy_simulation\n",
    "                    elif attr == 'energy_simulation':\n",
    "                        if hasattr(obj, 'solar_generation'):\n",
    "                            solar_gen = getattr(obj, 'solar_generation')\n",
    "                            print(f\"   ‚îî‚îÄ solar_generation: length={len(solar_gen) if hasattr(solar_gen, '__len__') else 'N/A'}\")\n",
    "                        if hasattr(obj, 'non_shiftable_load'):\n",
    "                            load = getattr(obj, 'non_shiftable_load')\n",
    "                            print(f\"   ‚îî‚îÄ non_shiftable_load: length={len(load) if hasattr(load, '__len__') else 'N/A'}\")\n",
    "                            \n",
    "                    # For lists, show length\n",
    "                    elif hasattr(obj, '__len__'):\n",
    "                        print(f\"   ‚îî‚îÄ length: {len(obj)}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è  {attr}: None\")\n",
    "            else:\n",
    "                print(f\"‚ùå {attr}: NOT FOUND\")\n",
    "                \n",
    "        print(f\"\\nüí° Try accessing net_electricity_consumption...\")\n",
    "        if hasattr(building, 'net_electricity_consumption'):\n",
    "            net_elec = building.net_electricity_consumption\n",
    "            if hasattr(net_elec, '__len__') and len(net_elec) > 0:\n",
    "                print(f\"   Current consumption: {net_elec[-1]}\")\n",
    "            else:\n",
    "                print(f\"   Empty or invalid: {type(net_elec)}\")\n",
    "    else:\n",
    "        print(\"‚ùå No buildings found\")\n",
    "else:\n",
    "    print(\"‚ùå Environment not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b033b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detailed PV Investigation:\n",
      "‚úÖ PV object type: PV\n",
      "üìã PV attributes: ['DEFAULT_RANDOM_SEED_RANGE', 'DEFAULT_SECONDS_PER_TIME_STEP', 'autosize', 'autosize_config', 'available_nominal_power', 'efficiency', 'electricity_consumption', 'episode_tracker', 'get_generation', 'get_metadata', 'next_time_step', 'nominal_power', 'numpy_random_state', 'random_seed', 'reset', 'reset_time_step', 'seconds_per_time_step', 'time_step', 'time_step_ratio', 'uid', 'update_electricity_consumption']\n",
      "‚ùå electricity_generation: NOT FOUND\n",
      "üîç Generation-related attributes: ['get_generation']\n",
      "\n",
      "üîç Energy Simulation Solar Generation:\n",
      "‚úÖ solar_generation: <class 'numpy.ndarray'> (length: 2208)\n",
      "   First few values: [0. 0. 0. 0. 0.]\n",
      "   Current value: 0.0\n",
      "\n",
      "üîç Pricing Information:\n",
      "‚úÖ electricity_pricing: <class 'numpy.ndarray'> (length: 2208)\n",
      "   First few values: [0.03025 0.03025 0.03025 0.03025 0.03025]\n",
      "   Current value: 0.030249999836087227\n"
     ]
    }
   ],
   "source": [
    "# ========================= CHECK PV ELECTRICITY GENERATION =========================\n",
    "\n",
    "if 'sac_env' in locals():\n",
    "    env_copy = sac_env.unwrapped if hasattr(sac_env, 'unwrapped') else sac_env\n",
    "    building = env_copy.buildings[0]\n",
    "    \n",
    "    print(\"üîç Detailed PV Investigation:\")\n",
    "    if hasattr(building, 'pv') and building.pv is not None:\n",
    "        pv = building.pv\n",
    "        print(f\"‚úÖ PV object type: {type(pv).__name__}\")\n",
    "        \n",
    "        # Check all PV attributes\n",
    "        pv_attrs = [attr for attr in dir(pv) if not attr.startswith('_')]\n",
    "        print(f\"üìã PV attributes: {pv_attrs}\")\n",
    "        \n",
    "        # Check specifically for electricity_generation\n",
    "        if hasattr(pv, 'electricity_generation'):\n",
    "            elec_gen = pv.electricity_generation\n",
    "            print(f\"‚úÖ electricity_generation: {type(elec_gen)} (length: {len(elec_gen) if hasattr(elec_gen, '__len__') else 'N/A'})\")\n",
    "            if hasattr(elec_gen, '__len__') and len(elec_gen) > 0:\n",
    "                print(f\"   First few values: {elec_gen[:5] if len(elec_gen) >= 5 else elec_gen}\")\n",
    "                print(f\"   Current value: {elec_gen[-1]}\")\n",
    "        else:\n",
    "            print(f\"‚ùå electricity_generation: NOT FOUND\")\n",
    "            \n",
    "        # Check for other generation-related attributes\n",
    "        gen_attrs = [attr for attr in pv_attrs if 'gen' in attr.lower()]\n",
    "        if gen_attrs:\n",
    "            print(f\"üîç Generation-related attributes: {gen_attrs}\")\n",
    "            \n",
    "        # Try other common PV attributes\n",
    "        common_attrs = ['generation', 'power', 'output', 'production']\n",
    "        for attr in common_attrs:\n",
    "            if hasattr(pv, attr):\n",
    "                val = getattr(pv, attr)\n",
    "                print(f\"‚úÖ {attr}: {type(val)} (length: {len(val) if hasattr(val, '__len__') else 'N/A'})\")\n",
    "                \n",
    "    print(f\"\\nüîç Energy Simulation Solar Generation:\")\n",
    "    if hasattr(building, 'energy_simulation'):\n",
    "        energy_sim = building.energy_simulation\n",
    "        if hasattr(energy_sim, 'solar_generation'):\n",
    "            solar_gen = energy_sim.solar_generation\n",
    "            print(f\"‚úÖ solar_generation: {type(solar_gen)} (length: {len(solar_gen)})\")\n",
    "            print(f\"   First few values: {solar_gen[:5]}\")\n",
    "            print(f\"   Current value: {solar_gen[-1]}\")\n",
    "            \n",
    "    print(f\"\\nüîç Pricing Information:\")\n",
    "    if hasattr(building, 'pricing'):\n",
    "        pricing = building.pricing\n",
    "        if hasattr(pricing, 'electricity_pricing'):\n",
    "            elec_pricing = pricing.electricity_pricing\n",
    "            print(f\"‚úÖ electricity_pricing: {type(elec_pricing)} (length: {len(elec_pricing)})\")\n",
    "            print(f\"   First few values: {elec_pricing[:5]}\")\n",
    "            print(f\"   Current value: {elec_pricing[-1]}\")\n",
    "else:\n",
    "    print(\"‚ùå Environment not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d3a6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TESTING FIXED SAC AGENT EVALUATION\n",
      "==================================================\n",
      "‚úÖ SAC model found - starting fixed evaluation...\n",
      "SAC Episode 1/2 - Reward: 0.00, Cost: $0.00, Consumption: 0.00\n",
      "SAC Episode 2/2 - Reward: 0.00, Cost: $0.00, Consumption: 0.00\n",
      "\n",
      "üìä FIXED SAC EVALUATION RESULTS:\n",
      "Average Reward: 0.000\n",
      "Average Cost: $0.000\n",
      "Average Consumption: 0.000 kWh\n",
      "Average Solar Used: 401780.091 kWh\n",
      "‚úÖ Success: Solar generation tracked (401780.091 kWh)\n",
      "\n",
      "‚ö†Ô∏è  Zero reward still achieved - this indicates:\n",
      "   ‚Ä¢ SolarPenaltyReward function is very restrictive\n",
      "   ‚Ä¢ Agent may need more training episodes\n",
      "   ‚Ä¢ Consider trying different reward functions\n"
     ]
    }
   ],
   "source": [
    "# ========================= TEST FIXED EVALUATION =========================\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"TESTING FIXED SAC AGENT EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if SAC model is available\n",
    "if 'sac_model' in locals() and 'sac_env' in locals():\n",
    "    print(\"‚úÖ SAC model found - starting fixed evaluation...\")\n",
    "    \n",
    "    # Evaluate the trained SAC agent with fixed metrics\n",
    "    sac_results = evaluate_agent(sac_model, sac_env, episodes=2, agent_type=\"SAC\")\n",
    "    \n",
    "    print(f\"\\nüìä FIXED SAC EVALUATION RESULTS:\")\n",
    "    print(f\"Average Reward: {sac_results['avg_reward']:.3f}\")\n",
    "    print(f\"Average Cost: ${sac_results['avg_cost']:.3f}\")\n",
    "    print(f\"Average Consumption: {sac_results['avg_consumption']:.3f} kWh\")\n",
    "    print(f\"Average Solar Used: {sac_results['avg_solar_used']:.3f} kWh\")\n",
    "    \n",
    "    # Analysis\n",
    "    if sac_results['avg_cost'] > 0:\n",
    "        print(f\"\\n‚úÖ Success: Non-zero cost calculated (${sac_results['avg_cost']:.3f})\")\n",
    "    if sac_results['avg_consumption'] > 0:\n",
    "        print(f\"‚úÖ Success: Non-zero consumption calculated ({sac_results['avg_consumption']:.3f} kWh)\")\n",
    "    if sac_results['avg_solar_used'] > 0:\n",
    "        print(f\"‚úÖ Success: Solar generation tracked ({sac_results['avg_solar_used']:.3f} kWh)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Note: Solar generation is zero (nighttime or no solar)\")\n",
    "        \n",
    "    if sac_results['avg_reward'] == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Zero reward still achieved - this indicates:\")\n",
    "        print(f\"   ‚Ä¢ SolarPenaltyReward function is very restrictive\")\n",
    "        print(f\"   ‚Ä¢ Agent may need more training episodes\")\n",
    "        print(f\"   ‚Ä¢ Consider trying different reward functions\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå SAC model not found. Please run the training cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (citylearn_env)",
   "language": "python",
   "name": "citylearn_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
